{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c679e91a-4b3e-40e9-b745-bda667f65602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5509ae77-eba7-4da2-96ea-122979b1b0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28.1 in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install openai==0.27.8\n",
    "!pip install openai==0.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43d652e-0e3d-4270-86a0-42d21321d5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf47b06-5c33-4695-9681-c55ccc75aba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711cbb9b-6efb-490a-b59d-87049d579823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.16.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.3.0)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b519ea3b-ed66-48de-8045-55b0293c8057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  poppler-utils\n",
      "0 upgraded, 1 newly installed, 0 to remove and 3 not upgraded.\n",
      "Need to get 186 kB of archives.\n",
      "After this operation, 696 kB of additional disk space will be used.\n",
      "Ign:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.1\n",
      "Err:1 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.1\n",
      "  404  Not Found [IP: 91.189.91.81 80]\n",
      "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/poppler/poppler-utils_22.02.0-2ubuntu0.1_amd64.deb  404  Not Found [IP: 91.189.91.81 80]\n",
      "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118057d4-4422-4ff5-a6d0-b1ddfd831341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF==1.23.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.5 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF==1.23.5) (1.23.5)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4996acc-0019-4820-a9e5-a9bf8ede0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from time import time\n",
    "\n",
    "class Timer:\n",
    "    \"\"\"処理時間を表示するクラス\n",
    "    with Timer(prefix=f'pred cv={i}'):\n",
    "        y_pred_i = predict(model, loader=test_loader)\n",
    "    \n",
    "    with Timer(prefix='fit fold={} '.format(i)):\n",
    "        clf.fit(x_train, y_train, \n",
    "                eval_set=[(x_valid, y_valid)],  \n",
    "                early_stopping_rounds=100,\n",
    "                verbose=verbose)\n",
    "\n",
    "    with Timer(prefix='fit fold={} '.format(i), verbose=500):\n",
    "        clf.fit(x_train, y_train, \n",
    "                eval_set=[(x_valid, y_valid)],  \n",
    "                early_stopping_rounds=100,\n",
    "                verbose=verbose)\n",
    "    \"\"\"\n",
    "    def __init__(self, logger=None, format_str='{:.3f}[s]', prefix=None, suffix=None, sep=' ', verbose=0):\n",
    "\n",
    "        if prefix: format_str = str(prefix) + sep + format_str\n",
    "        if suffix: format_str = format_str + sep + str(suffix)\n",
    "        self.format_str = format_str\n",
    "        self.logger = logger\n",
    "        self.start = None\n",
    "        self.end = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    @property\n",
    "    def duration(self):\n",
    "        if self.end is None:\n",
    "            return 0\n",
    "        return self.end - self.start\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.end = time()\n",
    "        out_str = self.format_str.format(self.duration)\n",
    "        if self.logger:\n",
    "            self.logger.info(out_str)\n",
    "        else:\n",
    "            print(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33ef9dfa-36e9-4a57-a63c-92a07e9122e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2310.14587'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# 取得したいURL\n",
    "url = \"https://arxiv.org/abs/2310.14587\"\n",
    "identifier = re.search(r'/([^/]+)$', url).group(1)\n",
    "identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bdc12e3-ef8e-4fbc-9258-99d39ff5687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def download_pdf(link, save_path):\n",
    "    response = requests.get(link)\n",
    "    with open(save_path, 'wb') as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee4541b7-d839-4724-937d-14a525b56118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.pdf を削除しました。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files_to_remove = ['sample.pdf']\n",
    "\n",
    "for file in files_to_remove:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"{file} を削除しました。\")\n",
    "    else:\n",
    "        print(f\"{file} は存在しません。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "688f1828-1dcd-42f1-a70c-18b3602f967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://arxiv.org/pdf/\" + identifier\n",
    "\n",
    "# download_pdf(url, nougat_path)\n",
    "download_pdf(url, \"sample.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "785cb072-1a4c-47db-bdb2-f439357f67f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"./sample.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6e685c0-0a65-41c1-8ed4-f6871d44afa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Abstract',\n",
       "  'modern search engines are built on a stack of different components, including query un-\\nderstanding,'),\n",
       " ('1 Introduction',\n",
       "  'With the ever-increasing amount of information on the web, search engines have emerged as an\\nindispe'),\n",
       " ('3 Large Search Model',\n",
       "  'First-stage Retrieval\\nPre-ranking\\nRanking\\n~1000 documents \\n~100 documents\\nBillions of documents\\nLarg'),\n",
       " ('4 Proof-of-Concept Experiments',\n",
       "  'In this section, we present some proof-of-concept experiments to showcase the potential of our\\npropo'),\n",
       " ('9 Table 4. An example for answer generation. Our model generates an answer for the given query “rsa',\n",
       "  'definition key” conditioned on the top-100 retrieved contexts.\\nTable 3 indicates that our model outp')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "\n",
    "# PyMuPDFを使用してPDFファイルから全てのテキストを抽出\n",
    "def extract_text_with_pymupdf(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# テキストを抽出\n",
    "text_from_pdf = extract_text_with_pymupdf(pdf_path)\n",
    "def split_text_into_sections(text):\n",
    "    sections = []\n",
    "    current_section = None\n",
    "    last_section_number = 0  # 最後に抽出したセクションの番号\n",
    "    \n",
    "    # セクションのタイトルと開始位置を探すための正規表現パターン\n",
    "    section_pattern = re.compile(r'\\n(\\d+)\\n([^\\d\\n].+?)\\n', re.MULTILINE)\n",
    "    \n",
    "    # Abstractを探すための正規表現パターン\n",
    "    abstract_pattern = re.search(r'\\nabstract\\n(.*?)(?=\\n\\d+|$)', text.lower(), re.DOTALL)\n",
    "    if abstract_pattern:\n",
    "        sections.append({\n",
    "            'title': 'Abstract',\n",
    "            'content': abstract_pattern.group(1).strip(),\n",
    "            'start': abstract_pattern.start(),\n",
    "            'end': abstract_pattern.end()\n",
    "        })\n",
    "    \n",
    "    for match in section_pattern.finditer(text):\n",
    "        section_number = int(match.group(1))\n",
    "        section_title = match.group(2).strip()\n",
    "        \n",
    "        # セクション番号が前のセクション番号よりも大きいか確認\n",
    "        if section_number > last_section_number:\n",
    "            # \"Work in progress\"を含まないセクションを抽出\n",
    "            if \"work in progress\" not in section_title.lower():\n",
    "                if current_section:\n",
    "                    current_section['content'] = text[current_section['end']:match.start()].strip()\n",
    "                    sections.append(current_section)\n",
    "                section_start = match.start()\n",
    "                section_end = match.end()\n",
    "                current_section = {'title': f\"{section_number} {section_title}\", 'content': '', 'start': section_start, 'end': section_end}\n",
    "                last_section_number = section_number\n",
    "        \n",
    "    if current_section:\n",
    "        current_section['content'] = text[current_section['end']:].strip()\n",
    "        sections.append(current_section)\n",
    "    \n",
    "    return sections\n",
    "\n",
    "# テキストをセクションごとに分割\n",
    "sections = split_text_into_sections(text_from_pdf)\n",
    "\n",
    "# 分割されたセクションのタイトルと最初の100文字を表示\n",
    "[(section['title'], section['content'][:100]) for section in sections]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db9a39d-dc05-479b-a569-fd59fef9b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0c5a73e-14c5-4fb9-a2df-b1cce8c579ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5d45778-6ebc-4eaf-917d-10cfb0bdc425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6aefc00-08d2-4d95-b6ef-78c3f63d7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95a3970a-8b7c-49e0-9cb6-09f2bc901d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainOfDensity:\n",
    "    def __init__(self, model_name=\"gpt-3.5-turbo\"):\n",
    "        self.model_name = model_name\n",
    "    \n",
    "    def num_tokens_from_string(self, string: str) -> int:\n",
    "        \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "        encoding = tiktoken.encoding_for_model(self.model_name)\n",
    "        num_tokens = len(encoding.encode(string))\n",
    "        return num_tokens\n",
    "    \n",
    "    def create_prompt(self, text):\n",
    "        \"\"\"Creates a prompt for the Chain of Density task.\"\"\"\n",
    "        return f\"\"\"\n",
    "        Article: {text}\n",
    "\n",
    "        You will generate increasingly concise, entity-dense summaries of the above Article.\n",
    "\n",
    "        Repeat the following 2 steps 5 times.\n",
    "\n",
    "        Step 1. Identify 1-3 informative Entities (\";\" delimited) from the Article which are missing from the previously generated summary.\n",
    "        Step 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the Missing Entities.\n",
    "\n",
    "        A Missing Entity is:\n",
    "        - Relevant: to the main story.\n",
    "        - Specific: descriptive yet concise (5 words or fewer).\n",
    "        - Novel: not in the previous summary.\n",
    "        - Faithful: present in the Article.\n",
    "        - Anywhere: located anywhere in the Article.\n",
    "\n",
    "        Guidelines:\n",
    "        - The first summary should be long (4-5 sentences, ~80 words) yet highly non-specific, containing little information beyond the entities marked as missing. Use overly verbose language and fillers (e.g., \"this article discusses\") to reach ~80 words.\n",
    "        - Make every word count: re-write the previous summary to improve flow and make space for additional entities.\n",
    "        - Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n",
    "        - The summaries should become highly dense and concise yet self-contained, e.g., easily understood without the Article.\n",
    "        - Missing entities can appear anywhere in the new summary.\n",
    "        - Never drop entities from the previous summary. If space cannot be made, add fewer new entities. Remember, use the exact same number of words for each summary. \n",
    "\n",
    "        Answer in JSON. The JSON should be a list (length 5) of dictionaries whose keys are \"Missing_Entities\" and \"Denser_Summary\"\n",
    "        Finally, output must be in Japanese.\n",
    "        \"\"\"\n",
    "    \n",
    "    def generate_summary(self, text):\n",
    "        \"\"\"Generates a summary using the Chain of Density method.\"\"\"\n",
    "        token_count = self.num_tokens_from_string(text)\n",
    "        if token_count > 4096:\n",
    "            print(\"Warning: Input is too long. Splitting the input into smaller chunks.\")\n",
    "            # 文単位で分割\n",
    "            sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "            # 分割した文を4096トークンに収めるようにグループ化\n",
    "            chunks = []\n",
    "            current_chunk = \"\"\n",
    "            for sentence in sentences:\n",
    "                if len(current_chunk) + len(sentence) + 1 > 4096:\n",
    "                    chunks.append(current_chunk)\n",
    "                    current_chunk = sentence\n",
    "                else:\n",
    "                    current_chunk += (\" \" + sentence)\n",
    "            chunks.append(current_chunk)\n",
    "        else:\n",
    "            chunks = [text]\n",
    "\n",
    "        # 各チャンクに対してAPIを呼び出し\n",
    "        responses = []\n",
    "        for chunk in chunks:\n",
    "            prompt = self.create_prompt(chunk)\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=self.model_name,\n",
    "                messages=[\n",
    "                    {\"role\" : \"system\", \"content\" : \"Outputs should be generated in step by step.\"},\n",
    "                    {\"role\": \"system\", \"content\": \"Given the remaining options, what is the final answer in Japanese?\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.8,\n",
    "                n=1,\n",
    "                stop=None,\n",
    "                top_p=1,\n",
    "            )\n",
    "            responses.append(response['choices'][0]['message']['content'])\n",
    "\n",
    "        # 結果を結合して返す\n",
    "        formatted_summary = \" \".join(responses)\n",
    "        return formatted_summary\n",
    "    \n",
    "    def format_cod_output(self, cod_output):\n",
    "        \"\"\"Formats the output of Chain of Density to be a readable text.\"\"\"\n",
    "        try:\n",
    "            summaries = json.loads(cod_output)\n",
    "            formatted_summaries = \" \".join([summary['Denser_Summary'] for summary in summaries])\n",
    "            return formatted_summaries\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error: The output is not in valid JSON format.\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4244c44-10b3-4efe-97ef-3b74534490e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8303c9b1-947d-4094-b815-4f24e9c46c40",
   "metadata": {},
   "source": [
    "## アルゴリズム: IEP (Interact-Eliminate-Propose)\n",
    "1. Planning: 問題を理解し、可能な答えをk個提案します。\n",
    "2. Inferring: 各オプションについて推論します。\n",
    "    - オプションが真である場合の前提条件は何かを考えます。\n",
    "    - 必要に応じて関連情報を自問自答または検索して前提条件を取得します。\n",
    "    - オプションを仮説として考え、それがこれらの前提条件と一致するかどうかを確認します。\n",
    "3. Eliminating: 矛盾しているオプションを排除します。\n",
    "    - もし一致するならば続けます。\n",
    "    - もし矛盾するならば候補から削除します。\n",
    "4. Answering: 最終的な答えを提案します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476fe591-b339-4e3c-b667-3be1c50ea110",
   "metadata": {},
   "source": [
    "## 実装ステップ\n",
    "1. テキストの前処理: 各章のテキストをトークンの最大数に収まるように分割します。\n",
    "2. 要約の生成: 各章のテキストを使用して要約を生成します。\n",
    "3. 質問応答: 生成した要約を基に質問応答を行い、答えを絞り込みます。\n",
    "4. 最終答えの提案: 答えの候補から最も適したものを選び出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1dbdda5-5178-4c9c-b621-d315da170bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class IEP:\n",
    "    def __init__(self):\n",
    "        self.candidates = []\n",
    "    \n",
    "    def set_initial_candidates(self, initial_candidates):\n",
    "        self.candidates = initial_candidates\n",
    "    \n",
    "    def planning(self, text):\n",
    "        # ここでは単純にテキストを要約して候補を生成しています。\n",
    "        # 実際には、より複雑なロジックや外部の情報を利用して候補を生成することが考えられます。\n",
    "        prompt = [\n",
    "            {\"role\" : \"system\", \"content\" : \"Outputs should be generated in step by step.\"},\n",
    "            # {\"role\": \"system\", \"content\": \"Please understand the problem and propose 5 possible answers in short sentences in Japanese.\"},\n",
    "            # {\"role\": \"system\", \"content\": \"Please understand the problem and propose 5 possible answers in short sentences.\"},\n",
    "            {\"role\": \"system\", \"content\": \"Please understand the problem and propose multiple possible answers\"},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "        summary = self._call_openai_api(prompt)\n",
    "        return summary\n",
    "    \n",
    "    def inferring_and_eliminating(self):\n",
    "        remaining_candidates = self.candidates[:]\n",
    "        for candidate in self.candidates:\n",
    "            premise = f\"The premise if {candidate} is true is that {candidate} would logically follow from the given information.\"\n",
    "            prompt = [\n",
    "                {\"role\" : \"system\", \"content\" : \"Outputs should be generated in step by step.\"},\n",
    "                # {\"role\": \"system\", \"content\": \"Think the option as hypothesis. Whether it entails with those premises? Please answer in Japanese.\"},\n",
    "                {\"role\": \"system\", \"content\": \"Think the option as hypothesis. Whether it entails with those premises?\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Hypothesis: {candidate}\\nPremises: {premise}\"}\n",
    "            ]\n",
    "            entailment = self._call_openai_api(prompt)\n",
    "            \n",
    "            if \"矛盾\" in entailment or \"contradict\" in entailment.lower():\n",
    "                remaining_candidates.remove(candidate)\n",
    "            # similarity_to_contradiction = calculate_similarity(entailment, \"contradict\")\n",
    "            # similarity_to_inconsistency = calculate_similarity(entailment, \"矛盾\")\n",
    "            # if similarity_to_contradiction > 0.5 or similarity_to_inconsistency > 0.5:\n",
    "            #     remaining_candidates.remove(candidate)\n",
    "                \n",
    "        self.candidates = remaining_candidates\n",
    "        return self.candidates\n",
    "    \n",
    "    def answering(self):\n",
    "        if not self.candidates:\n",
    "            return \"答えることができる候補がありません。\"\n",
    "        elif len(self.candidates) == 1:\n",
    "            return self.candidates[0]\n",
    "        else:\n",
    "            prompt = [\n",
    "                {\"role\" : \"system\", \"content\" : \"Outputs should be generated in step by step.\"},\n",
    "                {\"role\": \"system\", \"content\": \"Given the remaining options, what is the final answer in Japanese?\"},\n",
    "                {\"role\": \"user\", \"content\": \", \".join(self.candidates)}\n",
    "            ]\n",
    "            final_answer = self._call_openai_api(prompt)\n",
    "            return final_answer\n",
    "    \n",
    "    def num_tokens_from_string(self, string: str, encoding_name: str) -> int:\n",
    "        \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "        encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "        num_tokens = len(encoding.encode(string))\n",
    "        return num_tokens\n",
    "    \n",
    "    def _call_openai_api(self, prompt):\n",
    "        model_name = \"gpt-3.5-turbo\"\n",
    "        # model=\"gpt-3.5-turbo-16k\",\n",
    "        # model=\"gpt-4-0613\",\n",
    "        # 入力メッセージの'user'ロールのテキストを取得\n",
    "        text = next((message['content'] for message in prompt if message['role'] == 'user'), None)\n",
    "        if text is None:\n",
    "            raise ValueError(\"User's message not found in the prompt.\")\n",
    "\n",
    "        # トークン数をチェック\n",
    "        token_count = self.num_tokens_from_string(text, model_name)\n",
    "        chunk_num = 0\n",
    "        if token_count > 4096:\n",
    "            print(\"Warning: Input is too long. Splitting the input into smaller chunks.\")\n",
    "            # 文単位で分割\n",
    "            sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "            # 分割した文を4096トークンに収めるようにグループ化\n",
    "            chunks = []\n",
    "            current_chunk = \"\"\n",
    "            for sentence in sentences:\n",
    "                if len(current_chunk) + len(sentence) + 1 > 4096:\n",
    "                    chunks.append(current_chunk)\n",
    "                    current_chunk = sentence\n",
    "                else:\n",
    "                    current_chunk += (\" \" + sentence)\n",
    "            chunks.append(current_chunk)\n",
    "            chunk_num += 1\n",
    "        else:\n",
    "            chunks = [text]\n",
    "            chunk_num += 1\n",
    "        \n",
    "        # 各チャンクに対してAPIを呼び出し\n",
    "        responses = []\n",
    "        # print(f\"チャンク数: {chunk_num}\")\n",
    "        if chunk_num >= 3:\n",
    "            # チャンク数があまりに多い場合は要約を実行しない\n",
    "            # CoDで要約してもいいかも\n",
    "            return text\n",
    "        for chunk in chunks:\n",
    "            # プロンプトの'user'ロールのテキストを更新\n",
    "            for message in prompt:\n",
    "                if message['role'] == 'user':\n",
    "                    message['content'] = chunk\n",
    "            \n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model_name,\n",
    "                messages=prompt,\n",
    "                temperature=0.8,\n",
    "                # max_tokens=800,  # 生成するトークンの最大数（入力と合算して4097以内に収める必要あり）\n",
    "                n=1,  # 生成するレスポンスの数\n",
    "                stop=None,  # 停止トークンの設定\n",
    "                top_p=1,  # トークン選択時の確率閾値\n",
    "            )\n",
    "            responses.append(response['choices'][0]['message']['content'])\n",
    "        \n",
    "        # 結果を結合して返す\n",
    "        return \" \".join(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f48bbd41-0b4a-41f8-a084-410b2c3c5472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPINION PAPER\n",
      "Large Search Model: Redefining Search Stack\n",
      "in the Era of LLMs\n",
      "Liang Wang∗, Nan Yang∗, Xiaolong Huang,\n",
      "Linjun Yang, Rangan Majumder, Furu Wei\n",
      "Microsoft Corporation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 論文タイトル\n",
    "with fitz.open(pdf_path) as doc:\n",
    "    page_num = 0\n",
    "    page = doc.load_page(page_num)\n",
    "    text = page.get_text()\n",
    "\n",
    "# Extract text until \"Abstract\" or \"ABSTRACT\"\n",
    "abstract_index = text.lower().find(\"abstract\")\n",
    "pdf_title = text[:abstract_index ] if abstract_index != -1 else \"Abstract not found\"\n",
    "print(pdf_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b273f889-076c-4b89-bd8e-eda8879ac890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Abstract',\n",
       " 'content': 'modern search engines are built on a stack of different components, including query un-\\nderstanding, retrieval, multi-stage ranking, and question answering, among others. these\\ncomponents are often optimized and deployed independently. in this paper, we introduce\\na novel conceptual framework called large search model, which redefines the conventional\\nsearch stack by unifying search tasks with one large language model (llm). all tasks are\\nformulated as autoregressive text generation problems, allowing for the customization of\\ntasks through the use of natural language prompts. this proposed framework capitalizes on\\nthe strong language understanding and reasoning capabilities of llms, offering the potential\\nto enhance search result quality while simultaneously simplifying the existing cumbersome\\nsearch stack. to substantiate the feasibility of this framework, we present a series of proof-\\nof-concept experiments and discuss the potential challenges associated with implementing\\nthis approach within real-world search systems.',\n",
       " 'start': 177,\n",
       " 'end': 1222}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66bb0165-2e8c-464c-b46a-5c4f480a31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoDのインスタンスを作成\n",
    "cod = ChainOfDensity()\n",
    "\n",
    "if pdf_title != \"Abstract not found\":\n",
    "    # CoDで要約を生成\n",
    "    formatted_summary = cod.generate_summary(sections[0]['content'])\n",
    "else:\n",
    "    formatted_summary = \"Abstract not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e97f796-62fd-4e4c-bfc1-c28a15999756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"Missing_Entities\": \"search stack; autoregressive text generation\",\n",
      "        \"Denser_Summary\": \"現代の検索エンジンは、検索スタックとして知られる複数のコンポーネントで構築されています。クエリの理解、検索、マルチステージのランキング、質問への回答などが含まれます。この論文では、大規模な検索モデルという新しい概念フレームワークを紹介します。このフレームワークでは、すべてのタスクを自己回帰的なテキスト生成問題として定式化し、自然言語のプロンプトを使用してタスクをカスタマイズすることができます。この提案されたフレームワークは、大規模な言語モデルの強力な言語理解と推論能力を活用し、既存の煩雑な検索スタックを簡素化しながら検索結果の品質を向上させる可能性を提供します。このフレームワークの実現可能性を確認するために、一連の概念実証実験を行い、実世界の検索システムへの実装に関連する潜在的な課題について議論します。\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"large language model; natural language prompts\",\n",
      "        \"Denser_Summary\": \"大規模な言語モデル（LLM）を使用した新しい概念フレームワークである大規模な検索モデルを紹介します。このフレームワークでは、すべてのタスクを自己回帰的なテキスト生成問題として定式化し、自然言語のプロンプトを使用してタスクをカスタマイズすることができます。この提案されたフレームワークは、大規模な言語モデルの強力な言語理解と推論能力を活用し、既存の煩雑な検索スタックを簡素化しながら検索結果の品質を向上させる可能性を提供します。\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"proof-of-concept experiments; real-world search systems\",\n",
      "        \"Denser_Summary\": \"提案された大規模な検索モデルの実現可能性を確認するために、一連の概念実証実験を行い、実世界の検索システムへの実装に関連する潜在的な課題について議論します。このフレームワークでは、大規模な言語モデル（LLM）を使用し、自然言語のプロンプトを使用して検索タスクをカスタマイズします。大規模な言語モデルの強力な言語理解と推論能力を活用することで、検索結果の品質を向上させることができます。\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"language understanding; reasoning capabilities\",\n",
      "        \"Denser_Summary\": \"大規模な言語モデル（LLM）の強力な言語理解と推論能力を活用した提案された大規模な検索モデルを紹介します。このフレームワークでは、すべてのタスクを自己回帰的なテキスト生成問題として定式化し、自然言語のプロンプトを使用してタスクをカスタマイズすることができます。これにより、検索結果の品質を向上させることができます。\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"enhance search result quality; simplify existing search stack\",\n",
      "        \"Denser_Summary\": \"提案された大規模な検索モデルは、既存の煩雑な検索スタックを簡素化しながら検索結果の品質を向上させる可能性を提供します。大規模な言語モデル（LLM）の強力な言語理解と推論能力を活用することで、検索結果の品質を向上させることができます。\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# \"Abstract\" or \"ABSTRACT\"の要約\n",
    "print(formatted_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a44e1cb-1d4a-4f69-b5dd-205c39623c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sections数: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"sections数: {len(sections)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7e391ae-5b33-415d-8e48-6499036e6e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Candidates:  5.266[s]\n",
      "\"Remaining Candidates:  29.084[s]\n",
      "最終的な答えは、論文はLSMフレームワークを紹介し、大規模な言語モデル（LLM）を使用してすべての検索タスクを統一することを目指していると述べています。このアプローチにより、検索結果の品質が向上し、既存の検索スタックが簡素化される可能性があります。LSMフレームワークの実現可能性は、概念実証実験によって支持されており、実世界の検索システムにおける実装に関連する潜在的な課題も議論されています。\n",
      "\"Final Answer:  3.769[s]\n",
      "\"Chapter: Abstract 38.119[s]\n",
      "\n",
      "==================================================\n",
      "\n",
      "\"Candidates:  10.025[s]\n",
      "\"Remaining Candidates:  22.889[s]\n",
      "最終的な答えは、2番のオプションです。\n",
      "\"Final Answer:  0.586[s]\n",
      "\"Chapter: 1 Introduction 33.501[s]\n",
      "\n",
      "==================================================\n",
      "\n",
      "\"Candidates:  6.244[s]\n",
      "\"Remaining Candidates:  22.904[s]\n",
      "このセクションでは、著者たちは大規模な検索モデルを使用した情報検索タスクの統合的なモデリングアプローチについて議論しています。彼らはこのアプローチを従来の検索スタックと比較し、大規模な検索モデルの課題一般化とカスタマイズ化の利点を強調しています。また、大規模な言語モデル（LLM）の大規模展開に伴うレイテンシとコストの課題についても議論しています。\n",
      "\n",
      "著者たちは、自然言語プロンプティングを使用して異なる検索タスクに合わせて大規模な検索モデルをカスタマイズすることを提案しています。彼らはLLMがテキストを生成するための2つの方法、コンテキスト内学習とインストラクションについて説明しています。また、異なる情報検索タスクの例と、それらがプロンプトをカスタマイズすることで大規模な検索モデル内でどのように具体化されるかについても説明しています。\n",
      "\n",
      "著者たちはまた、大規模な検索モデルでの長いコンテキストモデリングの重要性についても強調しています。彼らは現在のLLMが制限された量のコンテキストを処理する能力の制約と、効果的なコンテキストの長さを拡張するための課題について議論しています。彼らは、長いコンテキストをモデリングする能力の恩恵を受けることができる検索関連タスクについても言及しています。\n",
      "\n",
      "さらに、著者たちは検索モデルにマルチモーダルコンテンツを組み込む可能性にも注目しています。彼らは大規模なマルチモーダル基礎モデルが、プレーンテキストを超えたウェブコンテンツの深い理解を提供し、新しい検索体験を可能にすることを説明しています。また、より大きく、より堅牢なマルチモーダル基礎モデルの開発が急速に進化している研究分野であることも言及しています。\n",
      "\n",
      "最後に、著者たちは実世界の検索システムにLLMを展開する際の実用的な考慮事項について議論しています。推論効率、幻覚、人間の価値との調整、データフィルタリングやコンテンツモデレーションなどのセーフガードの必要性といった課題について言及しています。\n",
      "\n",
      "全体的に、このセクションでは大規模な検索モデルを使用した統合的なモデリングアプローチの概要を提供し、実世界の検索システムへの展開に伴う潜在的な利点と課題を強調しています。\n",
      "\"Final Answer:  16.653[s]\n",
      "\"Chapter: 3 Large Search Model 45.801[s]\n",
      "\n",
      "==================================================\n",
      "\n",
      "\"Candidates:  1.086[s]\n",
      "\"Remaining Candidates:  2.011[s]\n",
      "Based on the information provided, it is not possible to determine the GPT-4 Score (1-10) for the model generation.\n",
      "\"Final Answer:  0.000[s]\n",
      "\"Chapter: 4 Proof-of-Concept Experiments 3.096[s]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 各章に対してIEPを適用\n",
    "for section in sections[:-1]:\n",
    "    with Timer(prefix=f'\"Chapter: {section[\"title\"]}'):\n",
    "        # IEPのインスタンスを作成\n",
    "        iep = IEP()\n",
    "\n",
    "        # 章ごとの前提とする要約文章の生成\n",
    "        with Timer(prefix=f'\"Candidates: '):\n",
    "            initial_candidates = iep.planning(section['content']).split(\"\\n\")\n",
    "            # print(f\"{initial_candidates}\")\n",
    "            iep.set_initial_candidates(initial_candidates)\n",
    "        # 計画と生成文章を比較して矛盾がないかを確認\n",
    "        with Timer(prefix=f'\"Remaining Candidates: '):\n",
    "            remaining_candidates = iep.inferring_and_eliminating()\n",
    "            # print(f\"{remaining_candidates}\")\n",
    "        # 最終回答\n",
    "        with Timer(prefix=f'\"Final Answer: '):\n",
    "            final_answer = iep.answering()\n",
    "            print(f\"{final_answer}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b09425-1c0c-4a3e-a077-b38d92237334",
   "metadata": {},
   "source": [
    "画像の抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32ab4924-12dd-4fdc-b1bc-1b0fa90ec31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fitz in /usr/local/lib/python3.10/dist-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from fitz) (5.0.8)\n",
      "Requirement already satisfied: configparser in /usr/local/lib/python3.10/dist-packages (from fitz) (6.0.0)\n",
      "Requirement already satisfied: httplib2 in /usr/lib/python3/dist-packages (from fitz) (0.20.2)\n",
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from fitz) (5.1.0)\n",
      "Requirement already satisfied: nipype in /usr/local/lib/python3.10/dist-packages (from fitz) (1.8.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.23.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz) (2.0.3)\n",
      "Requirement already satisfied: pyxnat in /usr/local/lib/python3.10/dist-packages (from fitz) (1.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.11.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from configobj->fitz) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/lib/python3/dist-packages (from httplib2->fitz) (2.4.7)\n",
      "Requirement already satisfied: packaging>=17 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (23.2)\n",
      "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (8.1.7)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.0)\n",
      "Requirement already satisfied: prov>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.0.0)\n",
      "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.8.2)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (7.0.0)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.19.2)\n",
      "Requirement already satisfied: traits!=5.0,<6.4,>=4.6 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (6.3.2)\n",
      "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.9.0)\n",
      "Requirement already satisfied: etelemetry>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (0.3.1)\n",
      "Requirement already satisfied: looseversion in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2023.3)\n",
      "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (0.18.3)\n",
      "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (4.9.3)\n",
      "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (2.31.0)\n",
      "Requirement already satisfied: ci-info>=0.2 in /usr/local/lib/python3.10/dist-packages (from etelemetry>=0.2.0->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2022.12.7)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac66e9a7-9236-4572-82ee-62659afc1a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: PyMuPDF 1.23.5\n",
      "Uninstalling PyMuPDF-1.23.5:\n",
      "  Successfully uninstalled PyMuPDF-1.23.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting PyMuPDF\n",
      "  Using cached PyMuPDF-1.23.5-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.5 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.23.5)\n",
      "Using cached PyMuPDF-1.23.5-cp310-none-manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.23.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y PyMuPDF\n",
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8542ac2a-ceb1-40b5-962b-f7f5207bdb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fitz in /usr/local/lib/python3.10/dist-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from fitz) (5.0.8)\n",
      "Requirement already satisfied: configparser in /usr/local/lib/python3.10/dist-packages (from fitz) (6.0.0)\n",
      "Requirement already satisfied: httplib2 in /usr/lib/python3/dist-packages (from fitz) (0.20.2)\n",
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from fitz) (5.1.0)\n",
      "Requirement already satisfied: nipype in /usr/local/lib/python3.10/dist-packages (from fitz) (1.8.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.23.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz) (2.0.3)\n",
      "Requirement already satisfied: pyxnat in /usr/local/lib/python3.10/dist-packages (from fitz) (1.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.11.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from configobj->fitz) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/lib/python3/dist-packages (from httplib2->fitz) (2.4.7)\n",
      "Requirement already satisfied: packaging>=17 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (23.2)\n",
      "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (8.1.7)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.0)\n",
      "Requirement already satisfied: prov>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.0.0)\n",
      "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.8.2)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (7.0.0)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.19.2)\n",
      "Requirement already satisfied: traits!=5.0,<6.4,>=4.6 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (6.3.2)\n",
      "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.9.0)\n",
      "Requirement already satisfied: etelemetry>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (0.3.1)\n",
      "Requirement already satisfied: looseversion in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2023.3)\n",
      "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (0.18.3)\n",
      "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (4.9.3)\n",
      "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (2.31.0)\n",
      "Requirement already satisfied: ci-info>=0.2 in /usr/local/lib/python3.10/dist-packages (from etelemetry>=0.2.0->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2022.12.7)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5a2bd87-d500-43dd-8a3e-f10ee1ef13ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "\n",
    "# pdf_path = nougat_path\n",
    "pdf_path = \"sample.pdf\"\n",
    "doc = fitz.open(pdf_path)\n",
    "extracted_images = []\n",
    "\n",
    "for page in doc:\n",
    "    # ページからイメージを抽出\n",
    "    for img_index in page.get_images(full=True):\n",
    "        xref = img_index[0]\n",
    "        base_image = fitz.Pixmap(doc, xref)\n",
    "        pil_img = Image.frombytes(\"RGB\", [base_image.width, base_image.height], base_image.samples)\n",
    "        extracted_images.append(pil_img)\n",
    "\n",
    "# 最初の抽出された図を表示\n",
    "if extracted_images:\n",
    "    extracted_images[0].show()\n",
    "else:\n",
    "    \"このPDFには抽出可能な図が含まれていません。\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62529ee0-b571-4c87-af19-1bbfc13b991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in extracted_images:\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee433b7-9f2b-47d7-aa2f-060a4397e6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

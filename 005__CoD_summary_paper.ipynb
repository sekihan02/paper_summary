{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c679e91a-4b3e-40e9-b745-bda667f65602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5509ae77-eba7-4da2-96ea-122979b1b0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28.1 in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install openai==0.27.8\n",
    "!pip install openai==0.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43d652e-0e3d-4270-86a0-42d21321d5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf47b06-5c33-4695-9681-c55ccc75aba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711cbb9b-6efb-490a-b59d-87049d579823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.16.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.3.0)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b519ea3b-ed66-48de-8045-55b0293c8057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  poppler-utils\n",
      "0 upgraded, 1 newly installed, 0 to remove and 3 not upgraded.\n",
      "Need to get 186 kB of archives.\n",
      "After this operation, 696 kB of additional disk space will be used.\n",
      "Ign:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.1\n",
      "Err:1 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.1\n",
      "  404  Not Found [IP: 91.189.91.81 80]\n",
      "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/poppler/poppler-utils_22.02.0-2ubuntu0.1_amd64.deb  404  Not Found [IP: 91.189.91.81 80]\n",
      "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118057d4-4422-4ff5-a6d0-b1ddfd831341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF==1.23.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.5 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF==1.23.5) (1.23.5)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4996acc-0019-4820-a9e5-a9bf8ede0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from time import time\n",
    "\n",
    "class Timer:\n",
    "    \"\"\"処理時間を表示するクラス\n",
    "    with Timer(prefix=f'pred cv={i}'):\n",
    "        y_pred_i = predict(model, loader=test_loader)\n",
    "    \n",
    "    with Timer(prefix='fit fold={} '.format(i)):\n",
    "        clf.fit(x_train, y_train, \n",
    "                eval_set=[(x_valid, y_valid)],  \n",
    "                early_stopping_rounds=100,\n",
    "                verbose=verbose)\n",
    "\n",
    "    with Timer(prefix='fit fold={} '.format(i), verbose=500):\n",
    "        clf.fit(x_train, y_train, \n",
    "                eval_set=[(x_valid, y_valid)],  \n",
    "                early_stopping_rounds=100,\n",
    "                verbose=verbose)\n",
    "    \"\"\"\n",
    "    def __init__(self, logger=None, format_str='{:.3f}[s]', prefix=None, suffix=None, sep=' ', verbose=0):\n",
    "\n",
    "        if prefix: format_str = str(prefix) + sep + format_str\n",
    "        if suffix: format_str = format_str + sep + str(suffix)\n",
    "        self.format_str = format_str\n",
    "        self.logger = logger\n",
    "        self.start = None\n",
    "        self.end = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    @property\n",
    "    def duration(self):\n",
    "        if self.end is None:\n",
    "            return 0\n",
    "        return self.end - self.start\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.end = time()\n",
    "        out_str = self.format_str.format(self.duration)\n",
    "        if self.logger:\n",
    "            self.logger.info(out_str)\n",
    "        else:\n",
    "            print(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ef9dfa-36e9-4a57-a63c-92a07e9122e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2310.03533'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# 取得したいURL\n",
    "url = \"https://arxiv.org/abs/2310.03533\"\n",
    "identifier = re.search(r'/([^/]+)$', url).group(1)\n",
    "identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bdc12e3-ef8e-4fbc-9258-99d39ff5687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def download_pdf(link, save_path):\n",
    "    response = requests.get(link)\n",
    "    with open(save_path, 'wb') as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee4541b7-d839-4724-937d-14a525b56118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.pdf を削除しました。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files_to_remove = ['sample.pdf']\n",
    "\n",
    "for file in files_to_remove:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"{file} を削除しました。\")\n",
    "    else:\n",
    "        print(f\"{file} は存在しません。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "688f1828-1dcd-42f1-a70c-18b3602f967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://arxiv.org/pdf/\" + identifier\n",
    "\n",
    "# download_pdf(url, nougat_path)\n",
    "download_pdf(url, \"sample.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "785cb072-1a4c-47db-bdb2-f439357f67f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"./sample.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6e685c0-0a65-41c1-8ed4-f6871d44afa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1 arXiv:2310.03533v3  [cs.SE]  11 Oct 2023',\n",
       "  'proved advantageous in the field of Genetic Improvement [7].\\nThe Automated Regression Oracle simply '),\n",
       " ('2 Section XI: Crosscutting Open Research Topic',\n",
       "  'est \\non\\nfinal bot \\nresponse\\nSoftware \\ndevelopment \\nactivities\\nRequirement Engineering\\nDesign & Plann'),\n",
       " ('105 # of preprints',\n",
       "  '# in CS category\\n# w/ LLM in title or abstract\\n# in cs.SE or cs.PL w/ LLM in title or abstract\\nFig. ')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "\n",
    "# PyMuPDFを使用してPDFファイルから全てのテキストを抽出\n",
    "def extract_text_with_pymupdf(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# テキストを抽出\n",
    "text_from_pdf = extract_text_with_pymupdf(pdf_path)\n",
    "def split_text_into_sections(text):\n",
    "    sections = []\n",
    "    current_section = None\n",
    "    last_section_number = 0  # 最後に抽出したセクションの番号\n",
    "    \n",
    "    # セクションのタイトルと開始位置を探すための正規表現パターン\n",
    "    section_pattern = re.compile(r'\\n(\\d+)\\n([^\\d\\n].+?)\\n', re.MULTILINE)\n",
    "    \n",
    "    # Abstractを探すための正規表現パターン\n",
    "    abstract_pattern = re.search(r'\\nabstract\\n(.*?)(?=\\n\\d+|$)', text.lower(), re.DOTALL)\n",
    "    if abstract_pattern:\n",
    "        sections.append({\n",
    "            'title': 'Abstract',\n",
    "            'content': abstract_pattern.group(1).strip(),\n",
    "            'start': abstract_pattern.start(),\n",
    "            'end': abstract_pattern.end()\n",
    "        })\n",
    "    \n",
    "    for match in section_pattern.finditer(text):\n",
    "        section_number = int(match.group(1))\n",
    "        section_title = match.group(2).strip()\n",
    "        \n",
    "        # セクション番号が前のセクション番号よりも大きいか確認\n",
    "        if section_number > last_section_number:\n",
    "            # \"Work in progress\"を含まないセクションを抽出\n",
    "            if \"work in progress\" not in section_title.lower():\n",
    "                if current_section:\n",
    "                    current_section['content'] = text[current_section['end']:match.start()].strip()\n",
    "                    sections.append(current_section)\n",
    "                section_start = match.start()\n",
    "                section_end = match.end()\n",
    "                current_section = {'title': f\"{section_number} {section_title}\", 'content': '', 'start': section_start, 'end': section_end}\n",
    "                last_section_number = section_number\n",
    "        \n",
    "    if current_section:\n",
    "        current_section['content'] = text[current_section['end']:].strip()\n",
    "        sections.append(current_section)\n",
    "    \n",
    "    return sections\n",
    "\n",
    "# テキストをセクションごとに分割\n",
    "sections = split_text_into_sections(text_from_pdf)\n",
    "\n",
    "# 分割されたセクションのタイトルと最初の100文字を表示\n",
    "[(section['title'], section['content'][:100]) for section in sections]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4db9a39d-dc05-479b-a569-fd59fef9b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0c5a73e-14c5-4fb9-a2df-b1cce8c579ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5d45778-6ebc-4eaf-917d-10cfb0bdc425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6aefc00-08d2-4d95-b6ef-78c3f63d7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95a3970a-8b7c-49e0-9cb6-09f2bc901d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainOfDensity:\n",
    "    def __init__(self, model_name=\"gpt-3.5-turbo-0613\"):\n",
    "        self.model_name = model_name\n",
    "    \n",
    "    def num_tokens_from_string(self, string: str) -> int:\n",
    "        \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "        encoding = tiktoken.encoding_for_model(self.model_name)\n",
    "        num_tokens = len(encoding.encode(string))\n",
    "        return num_tokens\n",
    "    \n",
    "    def create_prompt(self, text):\n",
    "        \"\"\"Creates a prompt for the Chain of Density task.\"\"\"\n",
    "        return f\"\"\"\n",
    "        Article: {text}\n",
    "\n",
    "        You will generate increasingly concise, entity-dense summaries of the above Article.\n",
    "\n",
    "        Repeat the following 2 steps 5 times.\n",
    "\n",
    "        Step 1. Identify 1-3 informative Entities (\";\" delimited) from the Article which are missing from the previously generated summary.\n",
    "        Step 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the Missing Entities.\n",
    "\n",
    "        A Missing Entity is:\n",
    "        - Relevant: to the main story.\n",
    "        - Specific: descriptive yet concise (5 words or fewer).\n",
    "        - Novel: not in the previous summary.\n",
    "        - Faithful: present in the Article.\n",
    "        - Anywhere: located anywhere in the Article.\n",
    "\n",
    "        Guidelines:\n",
    "        - The first summary should be long (4-5 sentences, ~80 words) yet highly non-specific, containing little information beyond the entities marked as missing. Use overly verbose language and fillers (e.g., \"this article discusses\") to reach ~80 words.\n",
    "        - Make every word count: re-write the previous summary to improve flow and make space for additional entities.\n",
    "        - Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n",
    "        - The summaries should become highly dense and concise yet self-contained, e.g., easily understood without the Article.\n",
    "        - Missing entities can appear anywhere in the new summary.\n",
    "        - Never drop entities from the previous summary. If space cannot be made, add fewer new entities. Remember, use the exact same number of words for each summary. \n",
    "\n",
    "        Answer in JSON. The JSON should be a list (length 5) of dictionaries whose keys are \"Missing_Entities\" and \"Denser_Summary\"\n",
    "        Finally, output must be in Japanese.\n",
    "        \"\"\"\n",
    "    \n",
    "    def generate_summary(self, text):\n",
    "        \"\"\"Generates a summary using the Chain of Density method.\"\"\"\n",
    "        token_count = self.num_tokens_from_string(text)\n",
    "        if token_count > 4096:\n",
    "            print(\"Warning: Input is too long. Splitting the input into smaller chunks.\")\n",
    "            # 文単位で分割\n",
    "            sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "            # 分割した文を4096トークンに収めるようにグループ化\n",
    "            chunks = []\n",
    "            current_chunk = \"\"\n",
    "            for sentence in sentences:\n",
    "                if len(current_chunk) + len(sentence) + 1 > 4096:\n",
    "                    chunks.append(current_chunk)\n",
    "                    current_chunk = sentence\n",
    "                else:\n",
    "                    current_chunk += (\" \" + sentence)\n",
    "            chunks.append(current_chunk)\n",
    "        else:\n",
    "            chunks = [text]\n",
    "\n",
    "        # 各チャンクに対してAPIを呼び出し\n",
    "        responses = []\n",
    "        for chunk in chunks:\n",
    "            prompt = self.create_prompt(chunk)\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=self.model_name,\n",
    "                messages=[\n",
    "                    {\"role\" : \"system\", \"content\" : \"Outputs should be generated in step by step.\"},\n",
    "                    {\"role\": \"system\", \"content\": \"Given the remaining options, what is the final answer in Japanese?\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.8,\n",
    "                n=1,\n",
    "                stop=None,\n",
    "                top_p=1,\n",
    "            )\n",
    "            responses.append(response['choices'][0]['message']['content'])\n",
    "\n",
    "        # 結果を結合して返す\n",
    "        formatted_summary = \" \".join(responses)\n",
    "        return formatted_summary\n",
    "\n",
    "    def generate_final_summary(self, text):\n",
    "        \"\"\"Generates a final summary from the combined summaries.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Outputs should be generated in step by step.\"},\n",
    "            {\"role\": \"system\", \"content\": \"Given the remaining options, what is the final answer in Japanese?\"},\n",
    "            {\"role\": \"system\", \"content\": \"Please summarize all of the following sentences, no matter how long they may be, including all of the following information.\"},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model_name,\n",
    "            messages=messages,\n",
    "            temperature=0.8,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            top_p=1,\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']\n",
    "    \n",
    "    def format_cod_output(self, cod_output):\n",
    "        \"\"\"Formats the output of Chain of Density to be a readable text.\"\"\"\n",
    "        try:\n",
    "            summaries = json.loads(cod_output)\n",
    "            formatted_summaries = \" \".join([summary['Denser_Summary'] for summary in summaries])\n",
    "            return formatted_summaries\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error: The output is not in valid JSON format.\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4244c44-10b3-4efe-97ef-3b74534490e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f48bbd41-0b4a-41f8-a084-410b2c3c5472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Models for Software Engineering:\n",
      "Survey and Open Problems\n",
      "Angela Fan\n",
      "Generative AI Team\n",
      "Meta Platforms Inc.\n",
      "New York, NY, USA\n",
      "Beliz Gokkaya\n",
      "PyTorch Team\n",
      "Meta Platforms Inc.\n",
      "Menlo Park, CA, USA\n",
      "Mark Harman\n",
      "Instagram Product Foundation\n",
      "Meta Platforms Inc.\n",
      "London, UK\n",
      "Mitya Lyubarskiy\n",
      "Developer Infrastructure\n",
      "Meta Platforms Inc.\n",
      "London, UK\n",
      "Shubho Sengupta\n",
      "FAIR\n",
      "Meta Platforms Inc.\n",
      "Menlo Park, CA, USA\n",
      "Shin Yoo\n",
      "School of Computing\n",
      "KAIST\n",
      "Daejeon, Korea\n",
      "Jie M. Zhang\n",
      "Department of Informatics\n",
      "King’s College London\n",
      "London, UK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 論文タイトル\n",
    "with fitz.open(pdf_path) as doc:\n",
    "    page_num = 0\n",
    "    page = doc.load_page(page_num)\n",
    "    text = page.get_text()\n",
    "\n",
    "# Extract text until \"Abstract\" or \"ABSTRACT\"\n",
    "abstract_index = text.lower().find(\"abstract\")\n",
    "pdf_title = text[:abstract_index ] if abstract_index != -1 else \"Abstract not found\"\n",
    "print(pdf_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b273f889-076c-4b89-bd8e-eda8879ac890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '1 arXiv:2310.03533v3  [cs.SE]  11 Oct 2023',\n",
       " 'content': 'proved advantageous in the field of Genetic Improvement [7].\\nThe Automated Regression Oracle simply uses the existing\\nversion of the software system as a reference against which to\\nbenchmark output from any subsequent adaptions and changes.\\nOf course, there is a risk of ‘baking in’ functional incor-\\nrectness, since the Automated Regression Oracle cannot detect\\nwhat the system should do, but only capture what it currently\\ndoes. Therefore, the Automated Regression Oracle can test\\nonly for functional regressions so it is best suited to use cases\\nwhere the existing functionality is to be maintained. For ex-\\nample, for non-functional improvements such as performance\\noptimisation and for semantics-preserving refactoring.\\nThe input provided to an LLM will be a natural focus of\\ngrowing research, and we can expect a rapid development of\\nthe literature on prompt engineering and prompt optimisation\\n[8]. In this survey, we highlight existing work and open\\nchallenges for prompt engineering with regard to several\\nspecific aspects of software engineering.\\nThe output from an LLM need not be confined purely to\\ncode, but can also include other software engineering arte-\\nfacts, such as requirements, test cases, design diagrams, and\\ndocumentation. In general, the language-based nature of an\\nLLM, allows it to generate any linguistically-defined software\\nengineering artefact.\\nWe typically think of the software engineering artefact as\\nthe primary output of the LLM, but it is not the only output.\\nThe explanation provided with the primary output is also an\\nimportant output of any LLM. Our survey highlights the need\\nfor much more research, not only into optimising prompt\\nengineering (which focuses on the input to the LLM) but also\\nthe need for work on the optimisation of explanations provided\\nwith the primary output.\\nLLMs are inherently nondeterministic: the same prompt\\nproduces different answers on different inference executions\\n(unless the temperature is set to zero, which has often been\\nfound to be suboptimal over multiple executions) [9]. Further-\\nmore, irrespective of the temperature setting, subtle changes\\nin the prompt can lead to very different outputs [9]. As well\\nas motivating ‘prompt engineering’ and output processing, this\\nnondeterministic behaviour raises challenges for the scientific\\nevaluation of LLM-based Software Engineering:\\nIf results can vary each time we run the overall\\nengineering process, how can we determine whether\\na proposed technique achieves an advance over the\\nstate of the art?\\nThis is a problem that has already been well studied in the\\ncontext of Empirical Software Engineering [10] and Search\\nBased Software Engineering (SBSE) [11]. In particular, SBSE\\nbears many similarities to LLM-based Software Engineering,\\nsharing with it the need to achieve robust scientific evaluation\\nin the presence of noisy, non-deterministic, and incomplete\\nresults [12], [13]. There is, therefore, already a mature soft-\\nware engineering literature on just the kind of robust scientific\\nevaluation techniques needed to cater for LLM-based scientific\\nevaluation. For example, well-studied techniques, such as\\nparametric and non-parametric inferential statistics, are now\\nroutinely used to provide robust scientific conclusions in the\\npresence of highly non-deterministic algorithms in the SBSE\\ndiscipline.\\nTABLE I\\nA (ALL) DENOTES ALL PREPRINTS THAT ARE CATEGORISED UNDER CS\\n(COMPUTER SCIENCE). L (LLM) DENOTES PREPRINTS WHOSE TITLE OR\\nABSTRACT INCLUDES “LLM”, “LARGE LANGUAGE MODEL”, OR “GPT”.\\nL ∩ S DENOTES PREPRINTS IN CS.SE OR CS.PL CATEGORY WHOSE TITLE\\nOR ABSTRACT INCLUDES THE SAME KEYWORDS. NOTE THAT THE YEAR\\n2023 ONLY INCLUDES DATA UP TO 27 JULY 2023.\\nYear\\n|A|\\n|L|\\n|L ∩ S|\\n|L|\\n|A| (%)\\n|L∩S|\\n|L| (%)\\n2007\\n2,238\\n0\\n0\\n0.00\\n0.00\\n2008\\n3,645\\n0\\n0\\n0.00\\n0.00\\n2009\\n4,873\\n0\\n0\\n0.00\\n0.00\\n2010\\n7,543\\n0\\n0\\n0.00\\n0.00\\n2011\\n9,114\\n0\\n0\\n0.00\\n0.00\\n2012\\n12,316\\n0\\n0\\n0.00\\n0.00\\n2013\\n14,933\\n0\\n0\\n0.00\\n0.00\\n2014\\n16,320\\n0\\n0\\n0.00\\n0.00\\n2015\\n18,818\\n0\\n0\\n0.00\\n0.00\\n2016\\n23,707\\n0\\n0\\n0.00\\n0.00\\n2017\\n30,746\\n0\\n0\\n0.00\\n0.00\\n2018\\n41,927\\n0\\n0\\n0.00\\n0.00\\n2019\\n55,325\\n36\\n0\\n0.00\\n0.00\\n2020\\n71,431\\n99\\n5\\n0.00\\n5.05\\n2021\\n77,520\\n192\\n13\\n0.25\\n6.77\\n2022\\n81,964\\n434\\n45\\n0.53\\n10.36\\n2023\\n52,547\\n1,665\\n181\\n3.17\\n10.87\\nIn order to understand the growth trends within LLM-based\\nSoftware Engineering, we performed a manual analysis of data\\non the number of publications on specific topics from arXiv.\\nTable I contains the raw data1, which was manually extracted\\nfrom the arXiv metadata dump made publicly available via\\nKaggle (https://www.kaggle.com/datasets/Cornell-University/\\narxiv), accessed on the 27th. July 2023. We first filtered\\nout publications for which the classification code does not\\nstart with the cs prefix (i.e., Computer Science), resulting in\\ncolumn A.\\nTo identify Computer Science papers that are relevant to\\nLLMs, we filtered the publications into subcategories on\\nartificial intelligence (cs.AI), machine learning (cs.LG), neural\\nand evolutionary computation (cs.NE), software engineering\\n(cs.SE), and programming language (cs.PL) using the queries\\n“Large Language Model”, “LLM”, and “GPT” in either the\\ntitle or the abstract (we manually excluded instances of over-\\nloaded acronyms such as GPT for General Planning Tool),\\nresulting in column L. Finally, we used the same queries to\\nidentify LLM-based Software Engineering papers in software\\nengineering (cs.SE) and programming language (cs.PL). These\\nqueries are inherently approximate, so we confine ourselves\\nonly to conclusions based on overall trends for which there\\nis strong evidence rather than specific details of the numbers\\nobserved. Nevertheless, we report the raw numbers observed\\nto support replication by others.\\nFigure 2, shows the growth in the number of arXiv-\\npublished papers on Computer Science (|A|, in Blue), and on\\n1The numbers for 2023 are underestimated since the data was accessed in\\nJuly 2023.',\n",
       " 'start': 5015,\n",
       " 'end': 5059}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ec3b607-475d-4f26-bb11-db3f64933ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Missing_Entities\": \"Automated Regression Oracle; functional regressions\", \"Denser_Summary\": \"既存のソフトウェアシステムを基準にして、自動回帰オラクルはその後の適応と変更の出力を評価する。機能の再現テストしかできないため、既存の機能を維持する場合に最適。パフォーマンスの最適化や意味を保持するリファクタリングには適している。\"}\n"
     ]
    }
   ],
   "source": [
    "cod = ChainOfDensity()\n",
    "abst_summary = cod.generate_summary(sections[0]['content'])\n",
    "print(abst_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7e391ae-5b33-415d-8e48-6499036e6e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\"generate_summary:  8.967[s]\n",
      "自動回帰オラクルは、既存のソフトウェアシステムを参照として使用し、後続の適応と変更の出力をベンチマークにする。しかし、自動回帰オラクルはシステムが行うべきことを検出することはできず、現在の動作のみを捉えるため、機能的な不正確さを「焼き込む」リスクがある。そのため、自動回帰オラクルは機能の回帰テストのみを行うことができるため、既存の機能を維持する場合に最適である。例えば、パフォーマンスの最適化や意味を保持するリファクタリングなどの非機能的な改善に適している。プロンプトエンジニアリングとプロンプト最適化に関する既存の研究や課題を強調する本調査では、LLMへの入力は成長する研究の自然な焦点となる可能性があり、LLMの出力はコードに限定される必要はない。要件、テストケース、設計図、ドキュメンテーションなど、ソフトウェアエンジニアリングの他のアーティファクトも含めることができる。また、LLMの主な出力とともに提供される説明も重要な出力である。\n",
      "\"Final Answer:  8.700[s]\n",
      "\"Chapter: 1 arXiv:2310.03533v3  [cs.SE]  11 Oct 2023 17.667[s]\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\"generate_summary:  16.595[s]\n",
      "この記事では、ソフトウェア開発活動について議論されています。要件エンジニアリングや設計、コードの実装、テスト、保守、展開など、さまざまなフェーズがあります。さらに、ソフトウェアのテストやパフォーマンス改善、デバッグと修正、文書生成、新たなテストの生成など、さまざまな技術や手法が研究されています。\n",
      "\n",
      "この記事では、ソフトウェアの応答に関する情報や詳細も議論されています。\n",
      "\n",
      "また、要件エンジニアリングや設計、計画立案に関する情報や詳細も議論されています。\n",
      "\n",
      "さらに、コードの実装やテストに関する情報や詳細も議論されています。\n",
      "\"Final Answer:  5.149[s]\n",
      "\"Chapter: 2 Section XI: Crosscutting Open Research Topic 21.744[s]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CoDのインスタンスを作成\n",
    "cod = ChainOfDensity()\n",
    "# 各章に対してIEPを適用\n",
    "for section in sections[:-1]:\n",
    "    with Timer(prefix=f'\"Chapter: {section[\"title\"]}'):\n",
    "        # 章ごとの前提とする要約文章の生成\n",
    "        with Timer(prefix=f'\"generate_summary: '):\n",
    "            formatted_summary = cod.generate_summary(section['content']).split(\"\\n\")\n",
    "            # print(f\"{formatted_summary}\")\n",
    "            print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "        # 最終回答\n",
    "        with Timer(prefix=f'\"Final Answer: '):\n",
    "            final_answer = cod.generate_final_summary(str(formatted_summary))\n",
    "            print(f\"{final_answer}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b09425-1c0c-4a3e-a077-b38d92237334",
   "metadata": {},
   "source": [
    "画像の抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ab4924-12dd-4fdc-b1bc-1b0fa90ec31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac66e9a7-9236-4572-82ee-62659afc1a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y PyMuPDF\n",
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542ac2a-ceb1-40b5-962b-f7f5207bdb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a2bd87-d500-43dd-8a3e-f10ee1ef13ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "\n",
    "# pdf_path = nougat_path\n",
    "pdf_path = \"sample.pdf\"\n",
    "doc = fitz.open(pdf_path)\n",
    "extracted_images = []\n",
    "\n",
    "for page in doc:\n",
    "    # ページからイメージを抽出\n",
    "    for img_index in page.get_images(full=True):\n",
    "        xref = img_index[0]\n",
    "        base_image = fitz.Pixmap(doc, xref)\n",
    "        pil_img = Image.frombytes(\"RGB\", [base_image.width, base_image.height], base_image.samples)\n",
    "        extracted_images.append(pil_img)\n",
    "\n",
    "# 最初の抽出された図を表示\n",
    "if extracted_images:\n",
    "    extracted_images[0].show()\n",
    "else:\n",
    "    \"このPDFには抽出可能な図が含まれていません。\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62529ee0-b571-4c87-af19-1bbfc13b991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in extracted_images:\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee433b7-9f2b-47d7-aa2f-060a4397e6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

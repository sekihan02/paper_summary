{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28abd92-9f85-4f58-977e-3cbb33dfe26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m119.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.1.2\n",
      "    Uninstalling pip-23.1.2:\n",
      "      Successfully uninstalled pip-23.1.2\n",
      "Successfully installed pip-23.2.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f0f43f-0664-4dea-bac7-e2223a6f2f49",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\n",
      "  Obtaining dependency information for arxiv from https://files.pythonhosted.org/packages/f0/06/9b9d553d93e25ae27ec5ba794216afb1af248e43d85a35e922a85cbb396a/arxiv-1.4.8-py3-none-any.whl.metadata\n",
      "  Downloading arxiv-1.4.8-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting feedparser (from arxiv)\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m198.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sgmllib3k (from feedparser->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hDownloading arxiv-1.4.8-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=18c17adca6ae1040d97949762302fa3eadb15a62ef2b215fb317ef38beee4b43\n",
      "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
      "Successfully built sgmllib3k\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: sgmllib3k, feedparser, arxiv\n",
      "Successfully installed arxiv-1.4.8 feedparser-6.0.10 sgmllib3k-1.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting tiktoken\n",
      "  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/f4/2e/0adf6e264b996e263b1c57cad6560ffd5492a69beb9fd779ed0463d486bc/tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m143.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: python-dotenv, tiktoken\n",
      "Successfully installed python-dotenv-1.0.0 tiktoken-0.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/1e/9f/385c25502f437686e4aa715969e5eaf5c2cb5e5ffa7c5cdd52f3c6ae967a/openai-0.28.1-py3-none-any.whl.metadata\n",
      "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
      "Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m375.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: openai\n",
      "Successfully installed openai-0.28.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install arxiv\n",
    "!pip3 install python-dotenv tiktoken\n",
    "!pip3 install openai\n",
    "#==0.27.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a73f2f51-2af8-4924-939c-e5f08c62f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import arxiv\n",
    "import openai\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b052b9-0864-4791-b144-bbcce9933abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "891e7219-d84f-49d3-b928-3b54687ef89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "612b548f-a137-4909-a4eb-6028335e0635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65e30177-9973-42f1-88ef-ddb51edff296",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c94d88c-cace-48eb-ac0e-3b69e7625069",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM = \"\"\"\n",
    "### 指示 ###\n",
    "論文の内容を理解した上で，重要なポイントを箇条書きで3点書いてください。\n",
    "\n",
    "### 箇条書きの制約 ###\n",
    "- 最大3個\n",
    "- 日本語\n",
    "- 箇条書き1個を50文字以内\n",
    "\n",
    "### 対象とする論文の内容 ###\n",
    "{text}\n",
    "\n",
    "### 出力形式 ###\n",
    "タイトル(和名)\n",
    "\n",
    "- 箇条書き1\n",
    "- 箇条書き2\n",
    "- 箇条書き3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca866b4-777e-4e42-aa01-ae23811639de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arXivの更新頻度を加味して、5日前の論文を検索\n",
    "N_DAYS = 5\n",
    "MAX_RESULT = 24  # 取得する論文数の上限\n",
    "MODEL_NAME = \"gpt-3.5-turbo-0613\"\n",
    "# MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "TEMPERATURE = 0.8\n",
    "\n",
    "# テンプレートを用意\n",
    "QUERY_TEMPLATE = '%28 ti:%22{}%22 OR abs:%22{}%22 %29 AND submittedDate: [{} TO {}]'\n",
    "\n",
    "# 検索を行い、結果を取得する関数\n",
    "def search_arxiv(keyword):\n",
    "    # 2日前からN_DAYS前までの論文を検索\n",
    "    today = dt.datetime.today() - dt.timedelta(days=2)\n",
    "    base_date = today - dt.timedelta(days=N_DAYS)\n",
    "    query = QUERY_TEMPLATE.format(keyword, keyword, base_date.strftime(\"%Y%m%d%H%M%S\"), today.strftime(\"%Y%m%d%H%M%S\"))\n",
    "\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=MAX_RESULT,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "        sort_order=arxiv.SortOrder.Descending,\n",
    "    )\n",
    "\n",
    "    # results = [result for result in search.results() if set(result.categories) & CATEGORIES]\n",
    "    results = []\n",
    "    for result in search.results():\n",
    "        # カテゴリーチェック\n",
    "        # if not set(result.categories) & CATEGORIES:\n",
    "        #     continue\n",
    "        # 要約内でのキーワードの存在チェック\n",
    "        if keyword.lower() in result.summary.lower():\n",
    "            results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 論文の要約を取得する関数\n",
    "def get_summary(result):\n",
    "    text = f\"title: {result.title}\\nbody: {result.summary}\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ]\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "    \n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88fcab98-4988-4ae9-bff5-16fd4e90cb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: uTalk: Bridging the Gap Between Humans and AI\n",
      "published: 2023-10-04 11:30:13+00:00\n",
      "abstruct: Large Language Models (LLMs) have revolutionized various industries by\n",
      "harnessing their power to improve productivity and facilitate learning across\n",
      "different fields. One intriguing application involves combining LLMs with\n",
      "visual models to create a novel approach to Human-Computer Interaction. The\n",
      "core idea behind this system is to develop an interactive platform that allows\n",
      "the general public to leverage the capabilities of ChatGPT in their daily\n",
      "lives. This is achieved by integrating several technologies such as Whisper,\n",
      "ChatGPT, Microsoft Speech Services, and the state-of-the-art (SOTA) talking\n",
      "head system, SadTalker, resulting in uTalk, an intelligent AI system. Users\n",
      "will be able to converse with this portrait, receiving answers to whatever\n",
      "questions they have in mind. Additionally, they could use uTalk for content\n",
      "generation by providing an input and their image. This system is hosted on\n",
      "Streamlit, where the user will initially be requested to provide an image to\n",
      "serve as their AI assistant. Then, users could choose whether to have a\n",
      "conversation or generate content based on their preferences. Either way, it\n",
      "starts by providing an input, where a set of operations will be done, and the\n",
      "avatar will provide a precise response. The paper discusses how SadTalker is\n",
      "optimized to improve its running time by 27.72% based on 25FPS generated\n",
      "videos. In addition, the system's initial performance, uTalk, improved further\n",
      "by 9.8% after SadTalker was integrated and parallelized with Streamlit.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02739v1\n",
      "summary: uTalk: 人間とAIのギャップを埋める\n",
      "\n",
      "- 大規模言語モデル（LLM）をビジュアルモデルと組み合わせることで、人間とコンピュータのインタラクションの新しいアプローチを実現する\n",
      "- Whisper、ChatGPT、Microsoft Speech Services、SadTalkerなどの技術を統合して、インテリジェントAIシステムuTalkを開発\n",
      "- SadTalkerの最適化により、実行時間が27.72％短縮され、Streamlitとの統合によりuTalkの性能がさらに9.8％向上した\n",
      "--------------------------------------------------\n",
      "title: How FaR Are Large Language Models From Agents with Theory-of-Mind?\n",
      "published: 2023-10-04 06:47:58+00:00\n",
      "abstruct: \"Thinking is for Doing.\" Humans can infer other people's mental states from\n",
      "observations--an ability called Theory-of-Mind (ToM)--and subsequently act\n",
      "pragmatically on those inferences. Existing question answering benchmarks such\n",
      "as ToMi ask models questions to make inferences about beliefs of characters in\n",
      "a story, but do not test whether models can then use these inferences to guide\n",
      "their actions. We propose a new evaluation paradigm for large language models\n",
      "(LLMs): Thinking for Doing (T4D), which requires models to connect inferences\n",
      "about others' mental states to actions in social scenarios. Experiments on T4D\n",
      "demonstrate that LLMs such as GPT-4 and PaLM 2 seemingly excel at tracking\n",
      "characters' beliefs in stories, but they struggle to translate this capability\n",
      "into strategic action. Our analysis reveals the core challenge for LLMs lies in\n",
      "identifying the implicit inferences about mental states without being\n",
      "explicitly asked about as in ToMi, that lead to choosing the correct action in\n",
      "T4D. To bridge this gap, we introduce a zero-shot prompting framework, Foresee\n",
      "and Reflect (FaR), which provides a reasoning structure that encourages LLMs to\n",
      "anticipate future challenges and reason about potential actions. FaR boosts\n",
      "GPT-4's performance from 50% to 71% on T4D, outperforming other prompting\n",
      "methods such as Chain-of-Thought and Self-Ask. Moreover, FaR generalizes to\n",
      "diverse out-of-distribution story structures and scenarios that also require\n",
      "ToM inferences to choose an action, consistently outperforming other methods\n",
      "including few-shot in-context learning.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.03051v1\n",
      "summary: 大規模言語モデルは他者の思考の推論を行う能力には優れているが、その推論を行動に結び付けることが難しい（T4D）。T4Dのためには、将来の課題を予測し、潜在的な行動について推論することが重要である。FaRはこれを実現するためのフレームワークであり、GPT-4の性能を向上させることができる。FaRは他の方法と比較しても優れた性能を発揮し、少数のコンテキスト学習を含む他のシナリオにも適用可能である。\n",
      "--------------------------------------------------\n",
      "title: Improving Automatic VQA Evaluation Using Large Language Models\n",
      "published: 2023-10-04 03:59:57+00:00\n",
      "abstruct: 8 years after the visual question answering (VQA) task was proposed, accuracy\n",
      "remains the primary metric for automatic evaluation. VQA Accuracy has been\n",
      "effective so far in the IID evaluation setting. However, our community is\n",
      "undergoing a shift towards open-ended generative models and OOD evaluation. In\n",
      "this new paradigm, the existing VQA Accuracy metric is overly stringent and\n",
      "underestimates the performance of VQA systems. Thus, there is a need to develop\n",
      "more robust automatic VQA metrics that serve as a proxy for human judgment. In\n",
      "this work, we propose to leverage the in-context learning capabilities of\n",
      "instruction-tuned large language models (LLMs) to build a better VQA metric. We\n",
      "formulate VQA evaluation as an answer-rating task where the LLM is instructed\n",
      "to score the accuracy of a candidate answer given a set of reference answers.\n",
      "We demonstrate the proposed metric better correlates with human judgment\n",
      "compared to existing metrics across several VQA models and benchmarks. We hope\n",
      "wide adoption of our metric will contribute to better estimating the research\n",
      "progress on the VQA task.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02567v1\n",
      "summary: 大規模言語モデルを使用した自動VQA評価の改善\n",
      "\n",
      "- VQAの評価指標であるVQA Accuracyは，開放型の生成モデルやOOD評価においては厳格すぎるため，VQAシステムの性能を過小評価している。\n",
      "- 提案されたメトリックは，複数のVQAモデルやベンチマークにおいて既存のメトリックと比較して人間の判断とより良い相関を示す。\n",
      "- 提案されたメトリックの広範な採用により，VQAタスクの研究進捗のより正確な推定に貢献することが期待される。\n",
      "--------------------------------------------------\n",
      "title: NOLA: Networks as Linear Combination of Low Rank Random Basis\n",
      "published: 2023-10-04 03:30:24+00:00\n",
      "abstruct: Large Language Models (LLMs) have recently gained popularity due to their\n",
      "impressive few-shot performance across various downstream tasks. However,\n",
      "fine-tuning all parameters and storing a unique model for each downstream task\n",
      "or domain becomes impractical because of the massive size of checkpoints (e.g.,\n",
      "350GB in GPT-3). Current literature, such as LoRA, showcases the potential of\n",
      "low-rank modifications to the original weights of an LLM, enabling efficient\n",
      "adaptation and storage for task-specific models. These methods can reduce the\n",
      "number of parameters needed to fine-tune an LLM by several orders of magnitude.\n",
      "Yet, these methods face two primary limitations: 1) the parameter reduction is\n",
      "lower-bounded by the rank one decomposition, and 2) the extent of reduction is\n",
      "heavily influenced by both the model architecture and the chosen rank. For\n",
      "instance, in larger models, even a rank one decomposition might exceed the\n",
      "number of parameters truly needed for adaptation. In this paper, we introduce\n",
      "NOLA, which overcomes the rank one lower bound present in LoRA. It achieves\n",
      "this by re-parameterizing the low-rank matrices in LoRA using linear\n",
      "combinations of randomly generated matrices (basis) and optimizing the linear\n",
      "mixture coefficients only. This approach allows us to decouple the number of\n",
      "trainable parameters from both the choice of rank and the network architecture.\n",
      "We present adaptation results using GPT-2 and ViT in natural language and\n",
      "computer vision tasks. NOLA performs as well as, or better than models with\n",
      "equivalent parameter counts. Furthermore, we demonstrate that we can halve the\n",
      "parameters in larger models compared to LoRA with rank one, without sacrificing\n",
      "performance.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02556v1\n",
      "summary: NOLA: Networks as Linear Combination of Low Rank Random Basis\n",
      "\n",
      "- LoRAと比較して、NOLAはランク1の下限を克服し、より効率的な適応とストレージを実現している。\n",
      "- NOLAはランクとネットワークアーキテクチャの選択から、訓練可能なパラメータの数を切り離すことができる。\n",
      "- NOLAは、LoRAのランク1と比較して、大きなモデルではパラメータを半分に減らすことができる。\n",
      "--------------------------------------------------\n",
      "title: Identifying Vulnerability Patches by Comprehending Code Commits with Comprehensive Change Contexts\n",
      "published: 2023-10-04 02:08:18+00:00\n",
      "abstruct: To help application developers apply vulnerability patches timely, security\n",
      "researchers maintain vulnerability databases such as National Vulnerability\n",
      "Database (NVD). By directly monitoring NVD with the name of each used library,\n",
      "application developers can be aware of vulnerabilities and their patches. Given\n",
      "that the monitoring results of vulnerability patches are unreliable due to\n",
      "patch incompleteness of NVD, existing approaches employ deep-learning (DL)\n",
      "models to identify additional vulnerability patches by determining whether a\n",
      "code commit fixes a vulnerability. However, these approaches suffer from low\n",
      "accuracy due to not considering code commits' comprehensive contexts such as\n",
      "control/data-flow contexts or method-invocation contexts. To improve accuracy,\n",
      "we design CompVPD, the first approach to identify vulnerability patches by\n",
      "fine-tuning a large language model (LLM) named StarCoder to comprehend code\n",
      "commits with comprehensive contexts. Considering that including comprehensive\n",
      "contexts needs to balance the context size and the training costs of LLM,\n",
      "CompVPD includes our two novel algorithms to generate comprehensive contexts\n",
      "within the given window size by removing irrelevant components (i.e., files,\n",
      "methods, and statements) and adaptively expanding each context. We empirically\n",
      "compare CompVPD with four state-of-the-art/practice (SOTA) approaches that\n",
      "identify vulnerability patches. The results show that CompVPD improves the AUC\n",
      "score by 11% and the F1 score by 30% when compared with the best scores of the\n",
      "SOTA approaches. Additionally, CompVPD provides high value to security practice\n",
      "by helping identify 20 vulnerability patches and 18 fixes of high-risk bugs\n",
      "from 2,500 recent code commits of five highly popular open-source projects.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02530v1\n",
      "summary: 脆弱性パッチを特定するための包括的な変更コンテキストを理解することで、CompVPDは脆弱性パッチを特定するための最初のアプローチを設計します。\n",
      "\n",
      "- NVDのパッチの不完全性による監視結果の信頼性の低さを改善するため、CompVPDはコードコミットが脆弱性を修正するかどうかを判断するために大規模な言語モデル（LLM）であるStarCoderを使用します。\n",
      "\n",
      "- このアプローチは、制御/データフローコンテキストやメソッド呼び出しコンテキストなどの包括的なコンテキストを考慮しないことによる低い精度に苦しんでいます。\n",
      "\n",
      "- CompVPDは、与えられたウィンドウサイズ内で包括的なコンテキストを生成するための2つの新しいアルゴリズムを含んでいます。これには、関係のないコンポーネント（ファイル、メソッド、文）を削除し、各コンテキストを適応的に拡大する必要があります。\n",
      "--------------------------------------------------\n",
      "title: CITING: Large Language Models Create Curriculum for Instruction Tuning\n",
      "published: 2023-10-04 01:58:34+00:00\n",
      "abstruct: The recent advancement of large language models (LLMs) has been achieved\n",
      "through a combo of instruction tuning and human alignment. However, building\n",
      "manually crafted instruction datasets and performing human alignment become the\n",
      "bottleneck for scaling the development of LLMs. In this paper, we exploit the\n",
      "idea of leveraging AI models in lieu of humans as the teacher to train student\n",
      "LLMs. Our method is inspired by how human students refine their writing skills\n",
      "by following the rubrics and learning from the revisions offered by their\n",
      "tutors. Specifically, we employ a teacher LLM to create a curriculum for\n",
      "instruction tuning of the student LLM, namely Curriculum Instruction TunING\n",
      "(CITING). It encompasses two main steps: (1) the teacher LLM crafts the rubrics\n",
      "for evaluating the answers corresponding to various types of questions, and (2)\n",
      "the student LLM learns to follow the rubrics and perform self-correction from\n",
      "the revision made by the teacher. We further iteratively carry out it to embody\n",
      "the procedure of CITING. We compare CITING to a series of state-of-the-art\n",
      "baselines on four datasets. Our method demonstrates strong improvement in terms\n",
      "of articulate, in-depth, and comprehensive by GPT-4 evaluation. Specifically,\n",
      "it achieves an average winning rate of 79.4% over SFT, 73.4% over RLHF, 78.1%\n",
      "over RRHF, and 76.3% over RAFT, respectively.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02527v1\n",
      "summary: CITING: 大規模言語モデルは、教示調整のためのカリキュラムを作成する\n",
      "\n",
      "- 大規模言語モデルの進歩は、教示調整と人間の調整の組み合わせによって実現されている。\n",
      "- LLMの開発をスケーリングするために、手動で作成した教示データセットと人間の調整がボトルネックになる。\n",
      "- CITINGは、教師LLMを利用して学生LLMの教示調整のためのカリキュラムを作成する方法であり、強力な改善を示している。\n",
      "--------------------------------------------------\n",
      "title: Large Language Models Can Be Good Privacy Protection Learners\n",
      "published: 2023-10-03 22:37:01+00:00\n",
      "abstruct: The proliferation of Large Language Models (LLMs) has driven considerable\n",
      "interest in fine-tuning them with domain-specific data to create specialized\n",
      "language models. Nevertheless, such domain-specific fine-tuning data often\n",
      "contains sensitive personally identifiable information (PII). Direct\n",
      "fine-tuning LLMs on this data without privacy protection poses a risk of\n",
      "leakage. To address this challenge, we introduce Privacy Protection Language\n",
      "Models (PPLM), a novel paradigm for fine-tuning LLMs that effectively injects\n",
      "domain-specific knowledge while safeguarding data privacy. Our work offers a\n",
      "theoretical analysis for model design and delves into various techniques such\n",
      "as corpus curation, penalty-based unlikelihood in training loss, and\n",
      "instruction-based tuning, etc. Extensive experiments across diverse datasets\n",
      "and scenarios demonstrate the effectiveness of our approaches. In particular,\n",
      "instruction tuning with both positive and negative examples, stands out as a\n",
      "promising method, effectively protecting private data while enhancing the\n",
      "model's knowledge. Our work underscores the potential for Large Language Models\n",
      "as robust privacy protection learners.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02469v1\n",
      "summary: 大規模言語モデルはプライバシー保護に有効な学習器となり得る\n",
      "\n",
      "- Privacy Protection Language Models (PPLM)は、データのプライバシー保護を実現しながら、ドメイン固有の知識を注入することができる\n",
      "- PPLMでは、コーパスのキュレーション、トレーニングロスでのペナルティベースの非願望度、指示に基づくチューニングなどのさまざまな技術が使用される\n",
      "- 多様なデータセットとシナリオでの実験により、PPLMのアプローチの効果が示される。特に、ポジティブとネガティブの両方の例を用いた指示チューニングは、モデルの知識を高めながらデータのプライバシーを効果的に保護する手法として優れている\n",
      "--------------------------------------------------\n",
      "title: EcoAssistant: Using LLM Assistant More Affordably and Accurately\n",
      "published: 2023-10-03 22:16:13+00:00\n",
      "abstruct: Today, users ask Large language models (LLMs) as assistants to answer queries\n",
      "that require external knowledge; they ask about the weather in a specific city,\n",
      "about stock prices, and even about where specific locations are within their\n",
      "neighborhood. These queries require the LLM to produce code that invokes\n",
      "external APIs to answer the user's question, yet LLMs rarely produce correct\n",
      "code on the first try, requiring iterative code refinement upon execution\n",
      "results. In addition, using LLM assistants to support high query volumes can be\n",
      "expensive. In this work, we contribute a framework, EcoAssistant, that enables\n",
      "LLMs to answer code-driven queries more affordably and accurately. EcoAssistant\n",
      "contains three components. First, it allows the LLM assistants to converse with\n",
      "an automatic code executor to iteratively refine code or to produce answers\n",
      "based on the execution results. Second, we use a hierarchy of LLM assistants,\n",
      "which attempts to answer the query with weaker, cheaper LLMs before backing off\n",
      "to stronger, expensive ones. Third, we retrieve solutions from past successful\n",
      "queries as in-context demonstrations to help subsequent queries. Empirically,\n",
      "we show that EcoAssistant offers distinct advantages for affordability and\n",
      "accuracy, surpassing GPT-4 by 10 points of success rate with less than 50% of\n",
      "GPT-4's cost.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.03046v1\n",
      "summary: EcoAssistant: LLMアシスタントをより手頃な価格で正確に使用するために\n",
      "\n",
      "- 外部知識が必要なクエリに対して、LLMアシスタントを使用することが多い。\n",
      "- LLMアシスタントは、初回の試行で正しいコードを生成することは稀であり、実行結果に基づいた反復的なコードの修正が必要とされる。\n",
      "- EcoAssistantは、コード駆動型のクエリに対して、LLMアシスタントが手頃な価格でより正確に回答するためのフレームワークである。\n",
      "--------------------------------------------------\n",
      "title: The Empty Signifier Problem: Towards Clearer Paradigms for Operationalising \"Alignment\" in Large Language Models\n",
      "published: 2023-10-03 22:02:17+00:00\n",
      "abstruct: In this paper, we address the concept of \"alignment\" in large language models\n",
      "(LLMs) through the lens of post-structuralist socio-political theory,\n",
      "specifically examining its parallels to empty signifiers. To establish a shared\n",
      "vocabulary around how abstract concepts of alignment are operationalised in\n",
      "empirical datasets, we propose a framework that demarcates: 1) which dimensions\n",
      "of model behaviour are considered important, then 2) how meanings and\n",
      "definitions are ascribed to these dimensions, and by whom. We situate existing\n",
      "empirical literature and provide guidance on deciding which paradigm to follow.\n",
      "Through this framework, we aim to foster a culture of transparency and critical\n",
      "evaluation, aiding the community in navigating the complexities of aligning\n",
      "LLMs with human populations.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02457v1\n",
      "summary: 大規模言語モデルにおける「アラインメント」の操作化に向けたより明確なパラダイムへの取り組み\n",
      "\n",
      "- 大規模言語モデルにおける「アラインメント」の概念を、ポスト構造主義の社会政治理論の観点から分析する。\n",
      "- 抽象的なアラインメントの概念を実証的なデータセットで操作化するための枠組みを提案する。\n",
      "- 既存の実証的文献を位置付け、どのパラダイムに従うかを判断するためのガイダンスを提供する。\n",
      "--------------------------------------------------\n",
      "title: Low-Resource Languages Jailbreak GPT-4\n",
      "published: 2023-10-03 21:30:56+00:00\n",
      "abstruct: AI safety training and red-teaming of large language models (LLMs) are\n",
      "measures to mitigate the generation of unsafe content. Our work exposes the\n",
      "inherent cross-lingual vulnerability of these safety mechanisms, resulting from\n",
      "the linguistic inequality of safety training data, by successfully\n",
      "circumventing GPT-4's safeguard through translating unsafe English inputs into\n",
      "low-resource languages. On the AdvBenchmark, GPT-4 engages with the unsafe\n",
      "translated inputs and provides actionable items that can get the users towards\n",
      "their harmful goals 79% of the time, which is on par with or even surpassing\n",
      "state-of-the-art jailbreaking attacks. Other high-/mid-resource languages have\n",
      "significantly lower attack success rate, which suggests that the cross-lingual\n",
      "vulnerability mainly applies to low-resource languages. Previously, limited\n",
      "training on low-resource languages primarily affects speakers of those\n",
      "languages, causing technological disparities. However, our work highlights a\n",
      "crucial shift: this deficiency now poses a risk to all LLMs users. Publicly\n",
      "available translation APIs enable anyone to exploit LLMs' safety\n",
      "vulnerabilities. Therefore, our work calls for a more holistic red-teaming\n",
      "efforts to develop robust multilingual safeguards with wide language coverage.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02446v1\n",
      "summary: 低リソース言語のGPT-4の回避が可能であることを示す\n",
      "- GPT-4の安全機構は、安全トレーニングデータの言語的不平等から生じるクロスリンガルな脆弱性を持つ\n",
      "- 低リソース言語への英語の翻訳を介してGPT-4の回避が成功する\n",
      "- 他の高リソース/中リソース言語は攻撃成功率が低く、クロスリンガルな脆弱性は主に低リソース言語に適用される\n",
      "--------------------------------------------------\n",
      "title: Novice Learner and Expert Tutor: Evaluating Math Reasoning Abilities of Large Language Models with Misconceptions\n",
      "published: 2023-10-03 21:19:50+00:00\n",
      "abstruct: We propose novel evaluations for mathematical reasoning capabilities of Large\n",
      "Language Models (LLMs) based on mathematical misconceptions. Our primary\n",
      "approach is to simulate LLMs as a novice learner and an expert tutor, aiming to\n",
      "identify the incorrect answer to math question resulted from a specific\n",
      "misconception and to recognize the misconception(s) behind an incorrect answer,\n",
      "respectively. Contrary to traditional LLMs-based mathematical evaluations that\n",
      "focus on answering math questions correctly, our approach takes inspirations\n",
      "from principles in educational learning sciences. We explicitly ask LLMs to\n",
      "mimic a novice learner by answering questions in a specific incorrect manner\n",
      "based on incomplete knowledge; and to mimic an expert tutor by identifying\n",
      "misconception(s) corresponding to an incorrect answer to a question. Using\n",
      "simple grade-school math problems, our experiments reveal that, while LLMs can\n",
      "easily answer these questions correctly, they struggle to identify 1) the\n",
      "incorrect answer corresponding to specific incomplete knowledge\n",
      "(misconceptions); 2) the misconceptions that explain particular incorrect\n",
      "answers. Our study indicates new opportunities for enhancing LLMs' math\n",
      "reasoning capabilities, especially on developing robust student simulation and\n",
      "expert tutoring models in the educational applications such as intelligent\n",
      "tutoring systems.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02439v1\n",
      "summary: 「誤解を持つ初心者学習者と専門家チューター：数学的推論能力を持つ大規模言語モデルの評価」\n",
      "\n",
      "- 著者は、大規模言語モデル（LLM）の数学的推論能力に関する新しい評価方法を提案している。\n",
      "- 伝統的な数学的評価では正確に問題に答えることに焦点を当てるのに対し、著者のアプローチは教育学の原則から着想を得たもので、LLMを初心者学習者と専門家チューターとしてシミュレートすることで、特定の誤った答えやその後に生じる誤解を特定することを目指している。\n",
      "- 実験結果は、LLMが簡単に問題に正解できる一方で、特定の不完全な知識（誤解）に基づいた誤った答えを特定するのに苦労し、また特定の誤った答えに対応する誤解を把握するのにも苦労していることを明らかにしている。\n",
      "--------------------------------------------------\n",
      "title: Can Large Language Models Provide Security & Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions\n",
      "published: 2023-10-03 20:54:29+00:00\n",
      "abstruct: Users seek security & privacy (S&P) advice from online resources, including\n",
      "trusted websites and content-sharing platforms. These resources help users\n",
      "understand S&P technologies and tools and suggest actionable strategies. Large\n",
      "Language Models (LLMs) have recently emerged as trusted information sources.\n",
      "However, their accuracy and correctness have been called into question. Prior\n",
      "research has outlined the shortcomings of LLMs in answering multiple-choice\n",
      "questions and user ability to inadvertently circumvent model restrictions\n",
      "(e.g., to produce toxic content). Yet, the ability of LLMs to provide reliable\n",
      "S&P advice is not well-explored. In this paper, we measure their ability to\n",
      "refute popular S&P misconceptions that the general public holds. We first study\n",
      "recent academic literature to curate a dataset of over a hundred S&P-related\n",
      "misconceptions across six different topics. We then query two popular LLMs\n",
      "(Bard and ChatGPT) and develop a labeling guide to evaluate their responses to\n",
      "these misconceptions. To comprehensively evaluate their responses, we further\n",
      "apply three strategies: query each misconception multiple times, generate and\n",
      "query their paraphrases, and solicit source URLs of the responses. Both models\n",
      "demonstrate, on average, a 21.3% non-negligible error rate, incorrectly\n",
      "supporting popular S&P misconceptions. The error rate increases to 32.6% when\n",
      "we repeatedly query LLMs with the same or paraphrased misconceptions. We also\n",
      "expose that models may partially support a misconception or remain\n",
      "noncommittal, refusing a firm stance on misconceptions. Our exploration of\n",
      "information sources for responses revealed that LLMs are susceptible to\n",
      "providing invalid URLs (21.2% for Bard and 67.7% for ChatGPT) or point to\n",
      "unrelated sources (44.2% returned by Bard and 18.3% by ChatGPT).\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02431v1\n",
      "summary: 大型言語モデル(LLMs)はS&P（セキュリティ＆プライバシー）の誤解を否定する能力を持つ\n",
      "- LLMsは一般の人々が持つS&Pに関する誤解を否定する能力を測定した\n",
      "- 平均して21.3%の誤った回答率があり、同じ誤解を複数回クエリすると32.6%に増加する\n",
      "- LLMsは誤ったURLを提供したり、関連のないソースを指摘することがある\n",
      "--------------------------------------------------\n",
      "title: AXNav: Replaying Accessibility Tests from Natural Language\n",
      "published: 2023-10-03 20:37:58+00:00\n",
      "abstruct: Developers and quality assurance testers often rely on manual testing to test\n",
      "accessibility features throughout the product lifecycle. Unfortunately, manual\n",
      "testing can be tedious, often has an overwhelming scope, and can be difficult\n",
      "to schedule amongst other development milestones. Recently, Large Language\n",
      "Models (LLMs) have been used for a variety of tasks including automation of\n",
      "UIs, however to our knowledge no one has yet explored their use in controlling\n",
      "assistive technologies for the purposes of supporting accessibility testing. In\n",
      "this paper, we explore the requirements of a natural language based\n",
      "accessibility testing workflow, starting with a formative study. From this we\n",
      "build a system that takes as input a manual accessibility test (e.g., ``Search\n",
      "for a show in VoiceOver'') and uses an LLM combined with pixel-based UI\n",
      "Understanding models to execute the test and produce a chaptered, navigable\n",
      "video. In each video, to help QA testers we apply heuristics to detect and flag\n",
      "accessibility issues (e.g., Text size not increasing with Large Text enabled,\n",
      "VoiceOver navigation loops). We evaluate this system through a 10 participant\n",
      "user study with accessibility QA professionals who indicated that the tool\n",
      "would be very useful in their current work and performed tests similarly to how\n",
      "they would manually test the features. The study also reveals insights for\n",
      "future work on using LLMs for accessibility testing.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02424v1\n",
      "summary: タイトル：AXNav: 自然言語からのアクセシビリティテストの再生\n",
      "\n",
      "- 手動テストは煩雑でスケジュールが立てにくく、開発の他のマイルストーンとの調整が難しい\n",
      "- 大規模な言語モデル（LLM）はUIの自動化に使用されるが、アクセシビリティテストの支援目的での使用はまだ探求されていない\n",
      "- LLMと画素ベースのUI理解モデルを組み合わせたシステムを構築し、手動のアクセシビリティテストを実行し、章立てでナビゲーション可能なビデオを生成することができる\n",
      "--------------------------------------------------\n",
      "title: Jailbreaker in Jail: Moving Target Defense for Large Language Models\n",
      "published: 2023-10-03 20:32:04+00:00\n",
      "abstruct: Large language models (LLMs), known for their capability in understanding and\n",
      "following instructions, are vulnerable to adversarial attacks. Researchers have\n",
      "found that current commercial LLMs either fail to be \"harmless\" by presenting\n",
      "unethical answers, or fail to be \"helpful\" by refusing to offer meaningful\n",
      "answers when faced with adversarial queries. To strike a balance between being\n",
      "helpful and harmless, we design a moving target defense (MTD) enhanced LLM\n",
      "system. The system aims to deliver non-toxic answers that align with outputs\n",
      "from multiple model candidates, making them more robust against adversarial\n",
      "attacks. We design a query and output analysis model to filter out unsafe or\n",
      "non-responsive answers. %to achieve the two objectives of randomly selecting\n",
      "outputs from different LLMs. We evaluate over 8 most recent chatbot models with\n",
      "state-of-the-art adversarial queries. Our MTD-enhanced LLM system reduces the\n",
      "attack success rate from 37.5\\% to 0\\%. Meanwhile, it decreases the response\n",
      "refusal rate from 50\\% to 0\\%.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02417v1\n",
      "summary: Jailbreaker in Jail: 大規模言語モデルのための移動ターゲットディフェンス\n",
      "\n",
      "- 大規模言語モデルは、不正な攻撃に対して脆弱であることがわかった。\n",
      "- 移動ターゲットディフェンス（MTD）を使用して、有害でなくても有用な回答を提供するシステムを設計した。\n",
      "- MTD-enhanced LLMシステムは、攻撃成功率を0%に減少させ、回答拒否率も0%に減少させることができた。\n",
      "--------------------------------------------------\n",
      "title: Automated Bug Generation in the era of Large Language Models\n",
      "published: 2023-10-03 20:01:51+00:00\n",
      "abstruct: Bugs are essential in software engineering; many research studies in the past\n",
      "decades have been proposed to detect, localize, and repair bugs in software\n",
      "systems. Effectiveness evaluation of such techniques requires complex bugs,\n",
      "i.e., those that are hard to detect through testing and hard to repair through\n",
      "debugging. From the classic software engineering point of view, a\n",
      "hard-to-repair bug differs from the correct code in multiple locations, making\n",
      "it hard to localize and repair. Hard-to-detect bugs, on the other hand,\n",
      "manifest themselves under specific test inputs and reachability conditions.\n",
      "These two objectives, i.e., generating hard-to-detect and hard-to-repair bugs,\n",
      "are mostly aligned; a bug generation technique can change multiple statements\n",
      "to be covered only under a specific set of inputs. However, these two\n",
      "objectives are conflicting for learning-based techniques: A bug should have a\n",
      "similar code representation to the correct code in the training data to\n",
      "challenge a bug prediction model to distinguish them. The hard-to-repair bug\n",
      "definition remains the same but with a caveat: the more a bug differs from the\n",
      "original code (at multiple locations), the more distant their representations\n",
      "are and easier to be detected. We propose BugFarm, to transform arbitrary code\n",
      "into multiple complex bugs. BugFarm leverages LLMs to mutate code in multiple\n",
      "locations (hard-to-repair). To ensure that multiple modifications do not\n",
      "notably change the code representation, BugFarm analyzes the attention of the\n",
      "underlying model and instructs LLMs to only change the least attended locations\n",
      "(hard-to-detect). Our comprehensive evaluation of 320k+ bugs from over 2.5M\n",
      "mutants generated by BugFarm and two alternative approaches demonstrates our\n",
      "superiority in generating bugs that are hard to detect by learning-based bug\n",
      "prediction approaches and hard to repair by SOTA learning-based program repair\n",
      "technique.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02407v1\n",
      "summary: 大規模言語モデルの時代における自動バグ生成\n",
      "\n",
      "- 複雑なバグを生成するためには、テストでは検出が困難であり、デバッグでも修正が困難なバグが必要。\n",
      "- 学習ベースのアプローチでは、バグの生成は正しいコードと似たコード表現を持つ必要があるが、修復が困難なバグほどコード表現が異なるため、判別が容易になる。\n",
      "- BugFarmは、LLMsを活用してコードを複数の箇所で変異させ、修復が困難なバグを生成する。また、コード表現が顕著に変わらないよう、最も注目されていない箇所のみを変更するように指示する。\n",
      "--------------------------------------------------\n",
      "title: Conversational Health Agents: A Personalized LLM-Powered Agent Framework\n",
      "published: 2023-10-03 18:54:10+00:00\n",
      "abstruct: Conversational Health Agents (CHAs) are interactive systems designed to\n",
      "enhance personal healthcare services by engaging in empathetic conversations\n",
      "and processing multimodal data. While current CHAs, especially those utilizing\n",
      "Large Language Models (LLMs), primarily focus on conversation, they often lack\n",
      "comprehensive agent capabilities. This includes the ability to access personal\n",
      "user health data from wearables, 24/7 data collection sources, and electronic\n",
      "health records, as well as integrating the latest published health insights and\n",
      "connecting with established multimodal data analysis tools. We are developing a\n",
      "framework to empower CHAs by equipping them with critical thinking, knowledge\n",
      "acquisition, and problem-solving abilities. Our CHA platform, powered by LLMs,\n",
      "seamlessly integrates healthcare tools, enables multilingual and multimodal\n",
      "conversations, and interfaces with a variety of user data analysis tools. We\n",
      "illustrate its proficiency in handling complex healthcare tasks, such as stress\n",
      "level estimation, showcasing the agent's cognitive and operational\n",
      "capabilities.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02374v1\n",
      "summary: Conversational Health Agents: A Personalized LLM-Powered Agent Framework\n",
      "\n",
      "- CHAs are interactive systems that enhance personal healthcare services through empathetic conversations and processing multimodal data.\n",
      "- Current CHAs, especially those using LLMs, often lack comprehensive agent capabilities.\n",
      "- The framework being developed aims to empower CHAs by equipping them with critical thinking, knowledge acquisition, and problem-solving abilities.\n",
      "--------------------------------------------------\n",
      "title: Reinforcement Learning from Automatic Feedback for High-Quality Unit Test Generation\n",
      "published: 2023-10-03 18:48:31+00:00\n",
      "abstruct: Software testing is a crucial aspect of software development, and the\n",
      "creation of high-quality tests that adhere to best practices is essential for\n",
      "effective maintenance. Recently, Large Language Models (LLMs) have gained\n",
      "popularity for code generation, including the automated creation of test cases.\n",
      "However, these LLMs are often trained on vast amounts of publicly available\n",
      "code, which may include test cases that do not adhere to best practices and may\n",
      "even contain test smells (anti-patterns). To address this issue, we propose a\n",
      "novel technique called Reinforcement Learning from Static Quality Metrics\n",
      "(RLSQM). To begin, we analyze the anti-patterns generated by the LLM and show\n",
      "that LLMs can generate undesirable test smells. Thus, we train specific reward\n",
      "models for each static quality metric, then utilize Proximal Policy\n",
      "Optimization (PPO) to train models for optimizing a single quality metric at a\n",
      "time. Furthermore, we amalgamate these rewards into a unified reward model\n",
      "aimed at capturing different best practices and quality aspects of tests. By\n",
      "comparing RL-trained models with those trained using supervised learning, we\n",
      "provide insights into how reliably utilize RL to improve test generation\n",
      "quality and into the effects of various training strategies. Our experimental\n",
      "results demonstrate that the RL-optimized model consistently generated\n",
      "high-quality test cases compared to the base LLM, improving the model by up to\n",
      "21%, and successfully generates nearly 100% syntactically correct code. RLSQM\n",
      "also outperformed GPT-4 on four out of seven metrics. This represents a\n",
      "significant step towards enhancing the overall efficiency and reliability of\n",
      "software testing through Reinforcement Learning and static quality metrics. Our\n",
      "data are available at this link: https://figshare.com/s/ded476c8d4c221222849.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02368v1\n",
      "summary: 単体テストの生成のための自動フィードバックからの強化学習\n",
      "\n",
      "- 大規模言語モデルはテストケースの自動生成に使用されるが、生成されるテストケースの品質が問題となることがある。\n",
      "- RLSQMは静的品質メトリクスを利用した強化学習の手法であり、テストケースの品質を最適化する。\n",
      "- RLSQMによって生成されたテストケースは、元のモデルよりも高品質であり、構文的に正しいコードをほぼ100%生成できる。\n",
      "--------------------------------------------------\n",
      "title: Contrastive Post-training Large Language Models on Data Curriculum\n",
      "published: 2023-10-03 17:59:46+00:00\n",
      "abstruct: Alignment serves as an important step to steer large language models (LLMs)\n",
      "towards human preferences. In this paper, we explore contrastive post-training\n",
      "techniques for alignment by automatically constructing preference pairs from\n",
      "multiple models of varying strengths (e.g., InstructGPT, ChatGPT and GPT-4). We\n",
      "carefully compare the contrastive techniques of SLiC and DPO to SFT baselines\n",
      "and find that DPO provides a step-function improvement even after continueing\n",
      "SFT saturates. We also explore a data curriculum learning scheme for\n",
      "contrastive post-training, which starts by learning from \"easier\" pairs and\n",
      "transitioning to \"harder\" ones, which further improves alignment. Finally, we\n",
      "scale up our experiments to train with more data and larger models like Orca.\n",
      "Remarkably, contrastive post-training further improves the performance of Orca,\n",
      "already a state-of-the-art instruction learning model tuned with GPT-4 outputs,\n",
      "to exceed that of ChatGPT.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02263v1\n",
      "summary: データカリキュラム上でコントラストポストトレーニングを実施することで、大規模言語モデルのアライメントを向上させる手法を提案している。\n",
      "- コントラストポストトレーニングの手法として、SLiCとDPOを比較し、DPOがSFTベースラインよりも優れた結果を示すことを示した。\n",
      "- データカリキュラム学習スキームを採用することで、より効果的なアライメントを実現できることを示した。\n",
      "- コントラストポストトレーニングは大規模モデルにもスケーラブルであり、既存のGPT-4を用いたOrcaモデルの性能をさらに向上させることができることを示した。\n",
      "--------------------------------------------------\n",
      "title: Generalizable Long-Horizon Manipulations with Large Language Models\n",
      "published: 2023-10-03 17:59:46+00:00\n",
      "abstruct: This work introduces a framework harnessing the capabilities of Large\n",
      "Language Models (LLMs) to generate primitive task conditions for generalizable\n",
      "long-horizon manipulations with novel objects and unseen tasks. These task\n",
      "conditions serve as guides for the generation and adjustment of Dynamic\n",
      "Movement Primitives (DMP) trajectories for long-horizon task execution. We\n",
      "further create a challenging robotic manipulation task suite based on Pybullet\n",
      "for long-horizon task evaluation. Extensive experiments in both simulated and\n",
      "real-world environments demonstrate the effectiveness of our framework on both\n",
      "familiar tasks involving new objects and novel but related tasks, highlighting\n",
      "the potential of LLMs in enhancing robotic system versatility and adaptability.\n",
      "Project website: https://object814.github.io/Task-Condition-With-LLM/\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02264v1\n",
      "summary: 一般化可能な長期の操作を大規模な言語モデルと共に行うフレームワーク\n",
      "\n",
      "- 大規模な言語モデル（LLMs）の能力を活用して、新しいオブジェクトと未知のタスクに対応するための基本的なタスク条件を生成するフレームワークを紹介する。\n",
      "- これらのタスク条件は、長期のタスク実行のためのダイナミックムーブメントプリミティブ（DMP）の軌道の生成と調整のためのガイドとして機能する。\n",
      "- シミュレーションと実世界の環境での広範な実験により、新しいオブジェクトを含む既存のタスクや関連するが新しいタスクに対しても、フレームワークの効果が示され、LLMsがロボットシステムの多様性と適応性を向上させる可能性を示している。\n",
      "--------------------------------------------------\n",
      "title: MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts\n",
      "published: 2023-10-03 17:57:24+00:00\n",
      "abstruct: Although Large Language Models (LLMs) and Large Multimodal Models (LMMs)\n",
      "exhibit impressive skills in various domains, their ability for mathematical\n",
      "reasoning within visual contexts has not been formally examined. Equipping LLMs\n",
      "and LMMs with this capability is vital for general-purpose AI assistants and\n",
      "showcases promising potential in education, data analysis, and scientific\n",
      "discovery. To bridge this gap, we present MathVista, a benchmark designed to\n",
      "amalgamate challenges from diverse mathematical and visual tasks. We first\n",
      "taxonomize the key task types, reasoning skills, and visual contexts from the\n",
      "literature to guide our selection from 28 existing math-focused and visual\n",
      "question answering datasets. Then, we construct three new datasets, IQTest,\n",
      "FunctionQA, and PaperQA, to accommodate for missing types of visual contexts.\n",
      "The problems featured often require deep visual understanding beyond OCR or\n",
      "image captioning, and compositional reasoning with rich domain-specific tools,\n",
      "thus posing a notable challenge to existing models. We conduct a comprehensive\n",
      "evaluation of 11 prominent open-source and proprietary foundation models (LLMs,\n",
      "LLMs augmented with tools, and LMMs), and early experiments with GPT-4V. The\n",
      "best-performing model, Multimodal Bard, achieves only 58% of human performance\n",
      "(34.8% vs 60.3%), indicating ample room for further improvement. Given this\n",
      "significant gap, MathVista fuels future research in the development of\n",
      "general-purpose AI agents capable of tackling mathematically intensive and\n",
      "visually rich real-world tasks. Preliminary tests show that MathVista also\n",
      "presents challenges to GPT-4V, underscoring the benchmark's importance. The\n",
      "project is available at https://mathvista.github.io/.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02255v1\n",
      "summary: MathVista: 数学的推論を視覚的な文脈で評価するための基盤モデルの評価\n",
      "\n",
      "- 数学的推論は、LLMsやLMMsにとって未だに課題であり、その能力を向上させることは重要である。\n",
      "- MathVistaは、数学的な課題と視覚的な課題を組み合わせたベンチマークであり、既存のモデルに対して非常に困難な問題を提供している。\n",
      "- 現時点で最も優れたモデルでも人間の性能の58%しか達成できず、改善の余地があることが示されている。\n",
      "--------------------------------------------------\n",
      "title: MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens\n",
      "published: 2023-10-03 17:49:04+00:00\n",
      "abstruct: Large Language Models (LLMs) have garnered significant attention for their\n",
      "advancements in natural language processing, demonstrating unparalleled prowess\n",
      "in text comprehension and generation. Yet, the simultaneous generation of\n",
      "images with coherent textual narratives remains an evolving frontier. In\n",
      "response, we introduce an innovative interleaved vision-and-language generation\n",
      "technique anchored by the concept of \"generative vokens,\" acting as the bridge\n",
      "for harmonized image-text outputs. Our approach is characterized by a\n",
      "distinctive two-staged training strategy focusing on description-free\n",
      "multimodal generation, where the training requires no comprehensive\n",
      "descriptions of images. To bolster model integrity, classifier-free guidance is\n",
      "incorporated, enhancing the effectiveness of vokens on image generation. Our\n",
      "model, MiniGPT-5, exhibits substantial improvement over the baseline Divter\n",
      "model on the MMDialog dataset and consistently delivers superior or comparable\n",
      "multimodal outputs in human evaluations on the VIST dataset, highlighting its\n",
      "efficacy across diverse benchmarks.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02239v1\n",
      "summary: MiniGPT-5: 画像とテキストの生成における交差するビジョンと言語の生成技術\n",
      "\n",
      "- テキストと画像の同時生成において、モデルの一貫性を保つために、「生成的ボーケン」という概念を導入した。\n",
      "- モデルの訓練において、詳細な画像の説明を必要としない多モーダルな生成を行うための二段階の訓練戦略を採用した。\n",
      "- 分類器を使用せずに、ボーケンの効果を向上させるためにガイド付き学習を取り入れた。\n",
      "--------------------------------------------------\n",
      "title: Who's Harry Potter? Approximate Unlearning in LLMs\n",
      "published: 2023-10-03 17:48:14+00:00\n",
      "abstruct: Large language models (LLMs) are trained on massive internet corpora that\n",
      "often contain copyrighted content. This poses legal and ethical challenges for\n",
      "the developers and users of these models, as well as the original authors and\n",
      "publishers. In this paper, we propose a novel technique for unlearning a subset\n",
      "of the training data from a LLM, without having to retrain it from scratch.\n",
      "  We evaluate our technique on the task of unlearning the Harry Potter books\n",
      "from the Llama2-7b model (a generative language model recently open-sourced by\n",
      "Meta). While the model took over 184K GPU-hours to pretrain, we show that in\n",
      "about 1 GPU hour of finetuning, we effectively erase the model's ability to\n",
      "generate or recall Harry Potter-related content, while its performance on\n",
      "common benchmarks (such as Winogrande, Hellaswag, arc, boolq and piqa) remains\n",
      "almost unaffected. We make our fine-tuned model publicly available on\n",
      "HuggingFace for community evaluation. To the best of our knowledge, this is the\n",
      "first paper to present an effective technique for unlearning in generative\n",
      "language models.\n",
      "  Our technique consists of three main components: First, we use a reinforced\n",
      "model that is further trained on the target data to identify the tokens that\n",
      "are most related to the unlearning target, by comparing its logits with those\n",
      "of a baseline model. Second, we replace idiosyncratic expressions in the target\n",
      "data with generic counterparts, and leverage the model's own predictions to\n",
      "generate alternative labels for every token. These labels aim to approximate\n",
      "the next-token predictions of a model that has not been trained on the target\n",
      "data. Third, we finetune the model on these alternative labels, which\n",
      "effectively erases the original text from the model's memory whenever it is\n",
      "prompted with its context.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02238v2\n",
      "summary: 『Who's Harry Potter? Approximate Unlearning in LLMs』\n",
      "\n",
      "- LLMのトレーニングデータから一部を削除するための新しい技術を提案\n",
      "- Harry Potter関連のコンテンツを削除するために、Llama2-7bモデルを1時間のファインチューニングで効果的に消去できることを示す\n",
      "- 3つの主要なコンポーネントからなる技術を使用する：(1) 強化モデルを使用して、アンラーニング対象に関連するトークンを特定する、(2) ターゲットデータ内の独自の表現を一般的な対応物に置き換える、(3) これらの代替ラベルでモデルをファインチューニングする\n",
      "--------------------------------------------------\n",
      "title: Extraction of Medication and Temporal Relation from Clinical Text by Harnessing Different Deep Learning Models\n",
      "published: 2023-10-03 17:37:22+00:00\n",
      "abstruct: Clinical texts, represented in electronic medical records (EMRs), contain\n",
      "rich medical information and are essential for disease prediction, personalised\n",
      "information recommendation, clinical decision support, and medication pattern\n",
      "mining and measurement. Relation extractions between medication mentions and\n",
      "temporal information can further help clinicians better understand the\n",
      "patients' treatment history. To evaluate the performances of deep learning (DL)\n",
      "and large language models (LLMs) in medication extraction and temporal\n",
      "relations classification, we carry out an empirical investigation of\n",
      "\\textbf{MedTem} project using several advanced learning structures including\n",
      "BiLSTM-CRF and CNN-BiLSTM for a clinical domain named entity recognition (NER),\n",
      "and BERT-CNN for temporal relation extraction (RE), in addition to the\n",
      "exploration of different word embedding techniques. Furthermore, we also\n",
      "designed a set of post-processing roles to generate structured output on\n",
      "medications and the temporal relation. Our experiments show that CNN-BiLSTM\n",
      "slightly wins the BiLSTM-CRF model on the i2b2-2009 clinical NER task yielding\n",
      "75.67, 77.83, and 78.17 for precision, recall, and F1 scores using Macro\n",
      "Average. BERT-CNN model also produced reasonable evaluation scores 64.48,\n",
      "67.17, and 65.03 for P/R/F1 using Macro Avg on the temporal relation extraction\n",
      "test set from i2b2-2012 challenges. Code and Tools from MedTem will be hosted\n",
      "at \\url{https://github.com/HECTA-UoM/MedTem}\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02229v1\n",
      "summary: 医療テキストからの薬物および時間的関係の抽出において、異なる深層学習モデルを活用する。\n",
      "\n",
      "- 医療テキストには重要な医療情報が含まれており、疾患予測、個別情報の推奨、臨床的な意思決定支援、薬物パターンの探索と分析に不可欠である。\n",
      "- 薬物の言及と時間情報の関係抽出は、患者の治療履歴をより良く把握するために医師を支援する。\n",
      "- BiLSTM-CRFやCNN-BiLSTMなどの進んだ学習構造と、医療領域の実体認識（NER）のためのBERT-CNNを用いて、薬物抽出と時間的関係の分類の性能を評価した。\n",
      "--------------------------------------------------\n",
      "title: Can Language Models be Instructed to Protect Personal Information?\n",
      "published: 2023-10-03 17:30:33+00:00\n",
      "abstruct: Large multimodal language models have proven transformative in numerous\n",
      "applications. However, these models have been shown to memorize and leak\n",
      "pre-training data, raising serious user privacy and information security\n",
      "concerns. While data leaks should be prevented, it is also crucial to examine\n",
      "the trade-off between the privacy protection and model utility of proposed\n",
      "approaches. In this paper, we introduce PrivQA -- a multimodal benchmark to\n",
      "assess this privacy/utility trade-off when a model is instructed to protect\n",
      "specific categories of personal information in a simulated scenario. We also\n",
      "propose a technique to iteratively self-moderate responses, which significantly\n",
      "improves privacy. However, through a series of red-teaming experiments, we find\n",
      "that adversaries can also easily circumvent these protections with simple\n",
      "jailbreaking methods through textual and/or image inputs. We believe PrivQA has\n",
      "the potential to support the development of new models with improved privacy\n",
      "protections, as well as the adversarial robustness of these protections. We\n",
      "release the entire PrivQA dataset at https://llm-access-control.github.io/.\n",
      "PDFリンク: http://arxiv.org/pdf/2310.02224v1\n",
      "summary: 個人情報の保護を指示できるか？(和名)\n",
      "\n",
      "- 大規模な多モーダル言語モデルは、実装された多くのアプリケーションで革新的な成果を上げている\n",
      "- これらのモデルは、事前学習データを記憶して漏洩することがあり、ユーザーのプライバシーや情報セキュリティに深刻な懸念を引き起こしている\n",
      "- プライバシー保護とモデルの有用性のトレードオフを評価するための多モーダルベンチマークとしてPrivQAを導入し、特定のカテゴリの個人情報を保護するようにモデルに指示するシミュレーションシナリオを提案する\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# CATEGORIES = {\n",
    "#     \"cs.AI\",  # 例: コンピュータサイエンスのAI分野\n",
    "#     # \"stat.ML\",  # 例: 統計学の機械学習分野\n",
    "#     # 必要に応じて他のカテゴリーを追加\n",
    "# }\n",
    "\n",
    "keyword = \"LLM\"\n",
    "results = search_arxiv(keyword)\n",
    "\n",
    "for result in results:\n",
    "    summary = get_summary(result)\n",
    "    print(f\"title: {result.title}\")\n",
    "    print(f\"published: {result.published}\")\n",
    "    print(f\"abstruct: {result.summary}\")\n",
    "    print(f\"PDFリンク: {result.pdf_url}\")\n",
    "    print(f\"summary: {summary}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9814b9f-ca7a-4a7b-ba39-3e09fc782a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

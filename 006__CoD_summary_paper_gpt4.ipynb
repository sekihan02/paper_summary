{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c679e91a-4b3e-40e9-b745-bda667f65602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5509ae77-eba7-4da2-96ea-122979b1b0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==1.2.0 in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.2.0) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.2.0) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.2.0) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.2.0) (1.10.13)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.2.0) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai==1.2.0) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.2.0) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.2.0) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai==1.2.0) (1.1.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.2.0) (2022.12.7)\n",
      "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.2.0) (1.0.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore->httpx<1,>=0.23.0->openai==1.2.0) (0.14.0)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install openai==0.27.8\n",
    "!pip install openai==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43d652e-0e3d-4270-86a0-42d21321d5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf47b06-5c33-4695-9681-c55ccc75aba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711cbb9b-6efb-490a-b59d-87049d579823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.16.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.3.0)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b519ea3b-ed66-48de-8045-55b0293c8057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  poppler-utils\n",
      "0 upgraded, 1 newly installed, 0 to remove and 3 not upgraded.\n",
      "Need to get 186 kB of archives.\n",
      "After this operation, 696 kB of additional disk space will be used.\n",
      "Ign:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.1\n",
      "Err:1 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.1\n",
      "  404  Not Found [IP: 185.125.190.39 80]\n",
      "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/poppler/poppler-utils_22.02.0-2ubuntu0.1_amd64.deb  404  Not Found [IP: 185.125.190.39 80]\n",
      "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118057d4-4422-4ff5-a6d0-b1ddfd831341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF==1.23.5\n",
      "  Using cached PyMuPDF-1.23.5-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting PyMuPDFb==1.23.5 (from PyMuPDF==1.23.5)\n",
      "  Using cached PyMuPDFb-1.23.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Using cached PyMuPDF-1.23.5-cp310-none-manylinux2014_x86_64.whl (4.3 MB)\n",
      "Using cached PyMuPDFb-1.23.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: PyMuPDFb, PyMuPDF\n",
      "  Attempting uninstall: PyMuPDFb\n",
      "    Found existing installation: PyMuPDFb 1.23.6\n",
      "    Uninstalling PyMuPDFb-1.23.6:\n",
      "      Successfully uninstalled PyMuPDFb-1.23.6\n",
      "  Attempting uninstall: PyMuPDF\n",
      "    Found existing installation: PyMuPDF 1.23.6\n",
      "    Uninstalling PyMuPDF-1.23.6:\n",
      "      Successfully uninstalled PyMuPDF-1.23.6\n",
      "Successfully installed PyMuPDF-1.23.5 PyMuPDFb-1.23.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33ef9dfa-36e9-4a57-a63c-92a07e9122e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2305.19234'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# 取得したいURL\n",
    "url = \"https://arxiv.org/abs/2305.19234\"\n",
    "identifier = re.search(r'/([^/]+)$', url).group(1)\n",
    "identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4996acc-0019-4820-a9e5-a9bf8ede0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from time import time\n",
    "\n",
    "class Timer:\n",
    "    \"\"\"処理時間を表示するクラス\n",
    "    with Timer(prefix=f'pred cv={i}'):\n",
    "        y_pred_i = predict(model, loader=test_loader)\n",
    "    \n",
    "    with Timer(prefix='fit fold={} '.format(i)):\n",
    "        clf.fit(x_train, y_train, \n",
    "                eval_set=[(x_valid, y_valid)],  \n",
    "                early_stopping_rounds=100,\n",
    "                verbose=verbose)\n",
    "\n",
    "    with Timer(prefix='fit fold={} '.format(i), verbose=500):\n",
    "        clf.fit(x_train, y_train, \n",
    "                eval_set=[(x_valid, y_valid)],  \n",
    "                early_stopping_rounds=100,\n",
    "                verbose=verbose)\n",
    "    \"\"\"\n",
    "    def __init__(self, logger=None, format_str='{:.3f}[s]', prefix=None, suffix=None, sep=' ', verbose=0):\n",
    "\n",
    "        if prefix: format_str = str(prefix) + sep + format_str\n",
    "        if suffix: format_str = format_str + sep + str(suffix)\n",
    "        self.format_str = format_str\n",
    "        self.logger = logger\n",
    "        self.start = None\n",
    "        self.end = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    @property\n",
    "    def duration(self):\n",
    "        if self.end is None:\n",
    "            return 0\n",
    "        return self.end - self.start\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.end = time()\n",
    "        out_str = self.format_str.format(self.duration)\n",
    "        if self.logger:\n",
    "            self.logger.info(out_str)\n",
    "        else:\n",
    "            print(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bdc12e3-ef8e-4fbc-9258-99d39ff5687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def download_pdf(link, save_path):\n",
    "    response = requests.get(link)\n",
    "    with open(save_path, 'wb') as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee4541b7-d839-4724-937d-14a525b56118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.pdf を削除しました。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files_to_remove = ['sample.pdf']\n",
    "\n",
    "for file in files_to_remove:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"{file} を削除しました。\")\n",
    "    else:\n",
    "        print(f\"{file} は存在しません。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "688f1828-1dcd-42f1-a70c-18b3602f967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://arxiv.org/pdf/\" + identifier\n",
    "\n",
    "# download_pdf(url, nougat_path)\n",
    "download_pdf(url, \"sample.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "785cb072-1a4c-47db-bdb2-f439357f67f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"./sample.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6e685c0-0a65-41c1-8ed4-f6871d44afa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Abstract',\n",
       "  'in this paper, we introduce textrank – a graph-based\\nranking model for text processing, and show how'),\n",
       " ('1 Introduction',\n",
       "  'Graph-based ranking algorithms like Kleinberg’s\\nHITS algorithm (Kleinberg,\\n1999) or Google’s\\nPageRan'),\n",
       " ('2 The TextRank Model',\n",
       "  'Graph-based ranking algorithms are essentially a\\nway of deciding the importance of a vertex within\\na'),\n",
       " ('3 \\x0f\\x0e\\x11\\x10\\x13\\x12\\x15\\x14\\x17\\x16\\x18',\n",
       "  'H�\\x19\\n\\nH\\n\\x0c\\n�\\n\\x1f! #\"\\n4\\n&\\nFigure 1 plots the convergence curves for the same\\nsample graph from section 2.'),\n",
       " ('4 Sentence Extraction',\n",
       "  'The other TextRank application that we investigate\\nconsists of sentence extraction for automatic sum'),\n",
       " ('24 [0.71]',\n",
       "  '[0.50]\\n21\\n20\\n19\\n18\\n17\\n16\\n15\\n14\\n13\\n12\\n11\\n10\\n9\\n8\\n7\\n6\\n5\\n4\\nHurricane Gilbert swept toward the Dominican ')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "\n",
    "# PyMuPDFを使用してPDFファイルから全てのテキストを抽出\n",
    "def extract_text_with_pymupdf(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# テキストを抽出\n",
    "text_from_pdf = extract_text_with_pymupdf(pdf_path)\n",
    "def split_text_into_sections(text):\n",
    "    sections = []\n",
    "    current_section = None\n",
    "    last_section_number = 0  # 最後に抽出したセクションの番号\n",
    "    \n",
    "    # セクションのタイトルと開始位置を探すための正規表現パターン\n",
    "    section_pattern = re.compile(r'\\n(\\d+)\\n([^\\d\\n].+?)\\n', re.MULTILINE)\n",
    "    \n",
    "    # Abstractを探すための正規表現パターン\n",
    "    abstract_pattern = re.search(r'\\nabstract\\n(.*?)(?=\\n\\d+|$)', text.lower(), re.DOTALL)\n",
    "    if abstract_pattern:\n",
    "        sections.append({\n",
    "            'title': 'Abstract',\n",
    "            'content': abstract_pattern.group(1).strip(),\n",
    "            'start': abstract_pattern.start(),\n",
    "            'end': abstract_pattern.end()\n",
    "        })\n",
    "    \n",
    "    for match in section_pattern.finditer(text):\n",
    "        section_number = int(match.group(1))\n",
    "        section_title = match.group(2).strip()\n",
    "        \n",
    "        # セクション番号が前のセクション番号よりも大きいか確認\n",
    "        if section_number > last_section_number:\n",
    "            # \"Work in progress\"を含まないセクションを抽出\n",
    "            if \"work in progress\" not in section_title.lower():\n",
    "                if current_section:\n",
    "                    current_section['content'] = text[current_section['end']:match.start()].strip()\n",
    "                    sections.append(current_section)\n",
    "                section_start = match.start()\n",
    "                section_end = match.end()\n",
    "                current_section = {'title': f\"{section_number} {section_title}\", 'content': '', 'start': section_start, 'end': section_end}\n",
    "                last_section_number = section_number\n",
    "        \n",
    "    if current_section:\n",
    "        current_section['content'] = text[current_section['end']:].strip()\n",
    "        sections.append(current_section)\n",
    "    \n",
    "    return sections\n",
    "\n",
    "# テキストをセクションごとに分割\n",
    "sections = split_text_into_sections(text_from_pdf)\n",
    "\n",
    "# 分割されたセクションのタイトルと最初の100文字を表示\n",
    "[(section['title'], section['content'][:100]) for section in sections]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4db9a39d-dc05-479b-a569-fd59fef9b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0c5a73e-14c5-4fb9-a2df-b1cce8c579ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5d45778-6ebc-4eaf-917d-10cfb0bdc425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6aefc00-08d2-4d95-b6ef-78c3f63d7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2570888-93db-4830-99e1-1d152c917e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95a3970a-8b7c-49e0-9cb6-09f2bc901d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainOfDensity:\n",
    "    def __init__(self, model_name=\"gpt-3.5-turbo-0613\"):\n",
    "        self.model_name = model_name\n",
    "    \n",
    "    def num_tokens_from_string(self, string: str) -> int:\n",
    "        \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "        encoding = tiktoken.encoding_for_model(self.model_name)\n",
    "        num_tokens = len(encoding.encode(string))\n",
    "        return num_tokens\n",
    "    \n",
    "#     def create_prompt(self, text):\n",
    "#         \"\"\"Creates a prompt for the Chain of Density task.\"\"\"\n",
    "#         return f\"\"\"\n",
    "#         Article: {text}\n",
    "\n",
    "#         You will generate increasingly concise, entity-dense summaries of the above Article.\n",
    "\n",
    "#         Repeat the following 2 steps 5 times.\n",
    "\n",
    "#         Step 1. Identify 1-3 informative Entities (\";\" delimited) from the Article which are missing from the previously generated summary.\n",
    "#         Step 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the Missing Entities.\n",
    "\n",
    "#         A Missing Entity is:\n",
    "#         - Relevant: to the main story.\n",
    "#         - Specific: descriptive yet concise (5 words or fewer).\n",
    "#         - Novel: not in the previous summary.\n",
    "#         - Faithful: present in the Article.\n",
    "#         - Anywhere: located anywhere in the Article.\n",
    "\n",
    "#         Guidelines:\n",
    "#         - The first summary should be long (4-5 sentences, ~80 words) yet highly non-specific, containing little information beyond the entities marked as missing. Use overly verbose language and fillers (e.g., \"this article discusses\") to reach ~80 words.\n",
    "#         - Make every word count: re-write the previous summary to improve flow and make space for additional entities.\n",
    "#         - Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n",
    "#         - The summaries should become highly dense and concise yet self-contained, e.g., easily understood without the Article.\n",
    "#         - Missing entities can appear anywhere in the new summary.\n",
    "#         - Never drop entities from the previous summary. If space cannot be made, add fewer new entities. Remember, use the exact same number of words for each summary. \n",
    "\n",
    "#         Answer in JSON. The JSON should be a list (length 5) of dictionaries whose keys are \"Missing_Entities\" and \"Denser_Summary\"\n",
    "#         Finally, output must be in Japanese.\n",
    "#         \"\"\"\n",
    "    def create_prompt(self, text):\n",
    "        \"\"\"Creates a prompt for an in-depth summary task.\"\"\"\n",
    "        return f\"\"\"\n",
    "        Article: {text}\n",
    "\n",
    "        Create five detailed, informative summaries of the article, each one more comprehensive and entity-dense than the previous. \n",
    "\n",
    "        For each round, perform the following steps:\n",
    "\n",
    "        Step 1. Identify 1-3 informative Entities (\";\" delimited) from the Article that were not included in the previous summary.\n",
    "        Step 2. Write a new, more detailed summary that incorporates all the entities and details from the previous summary plus the new Missing Entities.\n",
    "\n",
    "        A Missing Entity is:\n",
    "        - Relevant: to the main story.\n",
    "        - Specific: descriptive yet concise (5 words or fewer).\n",
    "        - Novel: not in the previous summary.\n",
    "        - Faithful: present in the Article.\n",
    "        - Anywhere: located anywhere in the Article.\n",
    "\n",
    "        Guidelines:\n",
    "        - Start with a comprehensive summary that encapsulates the article's main points and identified Missing Entities.\n",
    "        - With each subsequent summary, expand on the detail and depth, integrating the new Missing Entities into the narrative.\n",
    "        - Focus on improving the informativeness and clarity with each iteration.\n",
    "        - The final summary should offer a complete and nuanced understanding of the article's content.\n",
    "        - There is no word limit; instead, prioritize the inclusion of all relevant information and entities.\n",
    "        - The summaries should be well-structured and coherent, easily understood as standalone texts.\n",
    "        - Maintain the integrity of the information by ensuring that each summary is a faithful representation of the article.\n",
    "\n",
    "        The output should be in Japanese, structured in a JSON format as a list (length 5) of dictionaries with the keys \"Missing_Entities\" and \"Denser_Summary\".\n",
    "        \"\"\"\n",
    "\n",
    "    def generate_summary(self, text):\n",
    "        \"\"\"Generates a summary using the Chain of Density method.\"\"\"\n",
    "        prompt = self.create_prompt(text)\n",
    "        # response = openai.ChatCompletion.create(\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[\n",
    "                {\"role\" : \"system\", \"content\" : \"Outputs should be generated in step by step.\"},\n",
    "                {\"role\": \"system\", \"content\": \"Given the remaining options, what is the final answer in Japanese?\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.8,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            top_p=1,\n",
    "        )\n",
    "        # responses.append(response['choices'][0]['message']['content'])\n",
    "        return response.choices[0].message\n",
    "#         token_count = self.num_tokens_from_string(text)\n",
    "#         if token_count > 4096:\n",
    "#             print(\"Warning: Input is too long. Splitting the input into smaller chunks.\")\n",
    "#             # 文単位で分割\n",
    "#             sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "#             # 分割した文を4096トークンに収めるようにグループ化\n",
    "#             chunks = []\n",
    "#             current_chunk = \"\"\n",
    "#             for sentence in sentences:\n",
    "#                 if len(current_chunk) + len(sentence) + 1 > 4096:\n",
    "#                     chunks.append(current_chunk)\n",
    "#                     current_chunk = sentence\n",
    "#                 else:\n",
    "#                     current_chunk += (\" \" + sentence)\n",
    "#             chunks.append(current_chunk)\n",
    "#         else:\n",
    "#             chunks = [text]\n",
    "\n",
    "#         # 各チャンクに対してAPIを呼び出し\n",
    "#         responses = []\n",
    "#         for chunk in chunks:\n",
    "#             prompt = self.create_prompt(chunk)\n",
    "#             # response = openai.ChatCompletion.create(\n",
    "#             response = client.chat.completions.create(\n",
    "#                 model=self.model_name,\n",
    "#                 messages=[\n",
    "#                     {\"role\" : \"system\", \"content\" : \"Outputs should be generated in step by step.\"},\n",
    "#                     {\"role\": \"system\", \"content\": \"Given the remaining options, what is the final answer in Japanese?\"},\n",
    "#                     {\"role\": \"user\", \"content\": prompt}\n",
    "#                 ],\n",
    "#                 temperature=0.8,\n",
    "#                 n=1,\n",
    "#                 stop=None,\n",
    "#                 top_p=1,\n",
    "#             )\n",
    "#             # responses.append(response['choices'][0]['message']['content'])\n",
    "#             responses.append(response.choices[0].message)\n",
    "            \n",
    "\n",
    "#         # 結果を結合して返す\n",
    "#         formatted_summary = \" \".join(responses)\n",
    "#         return formatted_summary\n",
    "\n",
    "    def generate_final_summary(self, text):\n",
    "        \"\"\"Generates a final summary from the combined summaries.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Outputs should be generated in step by step.\"},\n",
    "            {\"role\": \"system\", \"content\": \"Given the remaining options, what is the final answer in Japanese?\"},\n",
    "            {\"role\": \"system\", \"content\": \"Please summarize all of the following sentences, no matter how long they may be, including all of the following information.\"},\n",
    "            {\"role\": \"system\", \"content\": \"出力は必ず日本語で生成してください。\"},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "        # response = openai.ChatCompletion.create(\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=messages,\n",
    "            temperature=0.8,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            top_p=1,\n",
    "        )\n",
    "        # return response['choices'][0]['message']['content']\n",
    "        return response.choices[0].message\n",
    "    \n",
    "    def format_cod_output(self, cod_output):\n",
    "        \"\"\"Formats the output of Chain of Density to be a readable text.\"\"\"\n",
    "        try:\n",
    "            summaries = json.loads(cod_output)\n",
    "            formatted_summaries = \" \".join([summary['Denser_Summary'] for summary in summaries])\n",
    "            return formatted_summaries\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error: The output is not in valid JSON format.\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f48bbd41-0b4a-41f8-a084-410b2c3c5472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextRank: Bringing Order into Texts\n",
      "Rada Mihalcea and Paul Tarau\n",
      "Department of Computer Science\n",
      "University of North Texas\n",
      "� rada,tarau\n",
      "� @cs.unt.edu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 論文タイトル\n",
    "with fitz.open(pdf_path) as doc:\n",
    "    page_num = 0\n",
    "    page = doc.load_page(page_num)\n",
    "    text = page.get_text()\n",
    "\n",
    "# Extract text until \"Abstract\" or \"ABSTRACT\"\n",
    "abstract_index = text.lower().find(\"abstract\")\n",
    "pdf_title = text[:abstract_index ] if abstract_index != -1 else \"Abstract not found\"\n",
    "print(pdf_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b273f889-076c-4b89-bd8e-eda8879ac890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Abstract',\n",
       " 'content': 'in this paper, we introduce textrank – a graph-based\\nranking model for text processing, and show how this\\nmodel can be successfully used in natural language\\napplications. in particular, we propose two innova-\\ntive unsupervised methods for keyword and sentence\\nextraction, and show that the results obtained com-\\npare favorably with previously published results on\\nestablished benchmarks.',\n",
       " 'start': 148,\n",
       " 'end': 545}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91d897f7-40f0-4a55-a661-1a903b9b089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_from_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ec3b607-475d-4f26-bb11-db3f64933ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Identify 1-3 informative Entities from the Article\n",
      "\n",
      "Missing Entities:\n",
      "1. TextRank\n",
      "2. Graph-based ranking model\n",
      "3. Natural Language Applications\n",
      "\n",
      "Step 2: Write a new, more detailed summary\n",
      "\n",
      "Denser Summary 1:\n",
      "この論文では、テキスト処理のためのグラフベースのランキングモデル「TextRank」を紹介し、このモデルを自然言語アプリケーションにうまく適用できることを示しています。特に、キーワードと文の抽出のための二つの革新的な教師なし方法を提案し、確立されたベンチマークでの既存の結果と比較して有利な結果が得られることを示しました。\n",
      "\n",
      "JSON Output:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"Missing_Entities\": \"TextRank; Graph-based ranking model; Natural Language Applications\",\n",
      "    \"Denser_Summary\": \"この論文では、テキスト処理のためのグラフベースのランキングモデル「TextRank」を紹介し、このモデルを自然言語アプリケーションにうまく適用できることを示しています。特に、キーワードと文の抽出のための二つの革新的な教師なし方法を提案し、確立されたベンチマークでの既存の結果と比較して有利な結果が得られることを示しました。\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Now let's move on to the next round of summary expansion.\n",
      "\n",
      "Step 1: Identify 1-3 informative Entities from the Article\n",
      "\n",
      "Missing Entities:\n",
      "1. Keyword extraction\n",
      "2. Sentence extraction\n",
      "3. Established benchmarks\n",
      "\n",
      "Step 2: Write a new, more detailed summary incorporating all previous entities and details plus the new Missing Entities.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "ステップ1: 記事から1〜3つの情報的なエンティティを特定する\n",
      "\n",
      "テキスト処理のためのグラフベースのランキングモデルである「TextRank」、自然言語アプリケーション、キーワード抽出、文抽出、確立されたベンチマーク。\n",
      "\n",
      "ステップ2: 全ての以前のエンティティと詳細に新たなエンティティを加え、より詳細な要約を書く\n",
      "\n",
      "この論文は、TextRankというテキスト処理を対象としたグラフベースのランキングモデルを紹介しており、このモデルを自然言語処理アプリケーションに適用することができるとしています。特に、キーワード抽出と文抽出のための新しい教師なしの方法を提案し、これらの方法が確立されたベンチマークに基づいた既存の結果を上回る有益な結果をもたらすことを示しています。\n"
     ]
    }
   ],
   "source": [
    "cod = ChainOfDensity(model_name=\"gpt-4-1106-preview\")\n",
    "abst_summary = cod.generate_summary(sections[0]['content'])\n",
    "print(abst_summary.content)\n",
    "final_answer = cod.generate_final_summary(str(abst_summary))\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "print(final_answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c3ba1-1518-4b8b-bcc2-756f4f72745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7e391ae-5b33-415d-8e48-6499036e6e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Identify 1-3 informative Entities from the Article\n",
      "\n",
      "- KleinbergのHITSアルゴリズム\n",
      "- GoogleのPageRank\n",
      "- ウェブ検索技術のパラダイムシフト\n",
      "\n",
      "Step 2: Write a new, more detailed summary\n",
      "\n",
      "初めの要約:\n",
      "KleinbergのHITSアルゴリズムやGoogleのPageRankなどのグラフベースのランキングアルゴリズムは、キュレーション分析、ソーシャルネットワーク、そしてウェブのリンク構造の分析に成功して使用されています。これらのアルゴリズムは、個別のウェブページのコンテンツ分析ではなく、ウェブ設計者の集合知に依存するウェブページのランキングメカニズムを提供することで、ウェブ検索技術の分野におけるパラダイムシフトを起こしたと言えるでしょう。\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"Missing_Entities\": \"KleinbergのHITSアルゴリズム;GoogleのPageRank;ウェブ検索技術のパラダイムシフト\",\n",
      "        \"Denser_Summary\": \"KleinbergのHITSアルゴリズムやGoogleのPageRankなどのグラフベースのランキングアルゴリズムは、キュレーション分析、ソーシャルネットワーク、そしてウェブのリンク構造の分析に成功して使用されています。これらのアルゴリズムは、ウェブページのランキングメカニズムにおいて、個々のコンテンツ分析ではなく、ウェブ設計者の集合知に依存することにより、ウェブ検索技術の分野におけるパラダイムシフトを引き起こしました。\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "\n",
      "Please let me know when you are ready to move on to the next summary.\n",
      "\"generate_summary:  16.062[s]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "ステップ1：記事から1から3の情報的なエンティティを特定する\n",
      "\n",
      "- KleinbergのHITSアルゴリズム\n",
      "- GoogleのPageRank\n",
      "- ウェブ検索技術のパラダイムシフト\n",
      "\n",
      "ステップ2：より詳細な要約を書く\n",
      "\n",
      "初めの要約:\n",
      "KleinbergのHITSアルゴリズムやGoogleのPageRankなどのグラフベースのランキングアルゴリズムは、キュレーション分析、ソーシャルネットワーク、そしてウェブのリンク構造の分析に成功して使用されています。これらのアルゴリズムは、個別のウェブページのコンテンツ分析ではなく、ウェブ設計者の集合知に依存するウェブページのランキングメカニズムを提供することで、ウェブ検索技術の分野におけるパラダイムシフトを起こしたと言えるでしょう。\n",
      "\n",
      "より詳細な要約:\n",
      "KleinbergのHITSアルゴリズムやGoogleのPageRankなどのグラフベースのランキングアルゴリズムは、キュレーション分析、ソーシャルネットワーク、そしてウェブのリンク構造の分析に成功して使用されています。これらのアルゴリズムは、ウェブページのランキングメカニズムにおいて、個々のコンテンツ分析ではなく、ウェブ設計者の集合知に依存することにより、ウェブ検索技術の分野におけるパラダイムシフトを引き起こしました。\n",
      "\n",
      "続いて、次の要約に進みますか？\n",
      "\"Final Answer:  17.718[s]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\"Chapter: 1 Introduction 33.780[s]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Step 1: Identify 1-3 informative Entities from the Article\n",
      "\n",
      "- グラフベースのランキングアルゴリズム (Graph-based ranking algorithms)\n",
      "- 頂点 (vertex)\n",
      "- グローバル情報 (global information)\n",
      "\n",
      "Step 2: Write a new, more detailed summary\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"Missing_Entities\": \"グラフベースのランキングアルゴリズム; 頂点; グローバル情報\",\n",
      "        \"Denser_Summary\": \"グラフベースのランキングアルゴリズムは頂点の重要性を決定する方法であり、グローバル情報をグラフ全体から再帰的に描き出すことに基づいています。\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "\n",
      "Proceed to the next summary iteration.\n",
      "\"generate_summary:  7.740[s]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "ステップ1: 記事から1-3の情報的なエンティティを特定する\n",
      "\n",
      "- グラフベースのランキングアルゴリズム\n",
      "- 頂点\n",
      "- グローバル情報\n",
      "\n",
      "ステップ2: より詳細な要約を書く\n",
      "\n",
      "グラフベースのランキングアルゴリズムは、グラフ内の頂点の重要性を決定する方法です。このアルゴリズムはグローバル情報を使用し、グラフ全体にわたり再帰的に情報を集めることに基づいています。\n",
      "\"Final Answer:  4.469[s]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\"Chapter: 2 The TextRank Model 12.209[s]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Step 1: Identify 1-3 informative Entities from the Article that were not included in the previous summary.\n",
      "\n",
      "Missing Entities:\n",
      "1. GenEx (Turney, 1999)\n",
      "2. Kea (Frank et al., 1999)\n",
      "3. Matlab code\n",
      "\n",
      "Step 2: Write a new, more detailed summary that incorporates all the entities and details from the previous summary plus the new Missing Entities.\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"Missing_Entities\": \"GenEx (Turney, 1999); Kea (Frank et al., 1999); Matlab code\",\n",
      "    \"Denser_Summary\": \"本稿では、テキストグラフに基づくランキングアルゴリズム、TextRankの適用例として、自然言語テキストからのキーワード抽出タスクと要約タスクの2つに焦点を当て検討した。TextRankは、テキスト内の単語やフレーズを頂点としてグラフに追加し、単語間の共起関係に基づいてエッジを引くことで、テキストを表現する。既存のキーワード抽出手法として、GenEx (Turney, 1999) システムや Kea (Frank et al., 1999) が挙げられるが、TextRankはこれらを上回る精度とF尺度を達成し、完全に教師なしで動作する点が特徴である。例えば、「Matlab code for plotting ambiguity functions」というテキストで、MatlabとcodeがTextRankによりキーワードとして選択された場合、隣接しているため「Matlab code」というマルチワードキーワードに統合される。\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please, let me know if you need the next iterations to continue the task.\n",
      "\"generate_summary:  14.470[s]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "ステップ1: 記事から以前の要約に含まれていなかった1〜3の情報エンティティを特定します。\n",
      "\n",
      "欠けているエンティティ:\n",
      "1. GenEx (Turney, 1999)\n",
      "2. Kea (Frank et al., 1999)\n",
      "3. Matlab コード\n",
      "\n",
      "ステップ2: 以前の要約に新たに特定されたエンティティと詳細を組み合わせて、より詳細な新しい要約を書きます。\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"Missing_Entities\": \"GenEx (Turney, 1999); Kea (Frank et al., 1999); Matlab コード\",\n",
      "    \"Denser_Summary\": \"本稿では、テキストグラフに基づくランキングアルゴリズムであるTextRankを自然言語テキストからキーワードを抽出するタスクと要約するタスクの2つの応用例に焦点を当てて検討しました。TextRankは、テキスト内の単語やフレーズを頂点としたグラフを作成し、単語間の共起関係に基づいてエッジを追加することでテキストをグラフ構造で表現します。既存のキーワード抽出手法としては、GenEx (Turney, 1999) システムや Kea (Frank et al., 1999) がありますが、TextRankはこれらの手法よりも精度とF尺度で優れた結果を示し、完全に教師なしで機能します。例えば、「Matlab code for plotting ambiguity functions」というフレーズでは、MatlabとcodeがTextRankによりキーワードとして選択されたとき、隣接しているため「Matlab code」というフレーズがマルチワードキーワードとしてまとめられます。\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "次の作業に進めるよう必要な情報を教えてください。\n",
      "\"Final Answer:  16.615[s]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\"Chapter: 3 \u000f\u000e\u0011\u0010\u0013\u0012\u0015\u0014\u0017\u0016\u0018 31.085[s]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Step 1: Identify 1-3 informative Entities from the Article\n",
      "\n",
      "Missing Entities:\n",
      "1. TextRankアルゴリズム\n",
      "2. 自動要約\n",
      "3. 文抽出\n",
      "\n",
      "Step 2: Write a new summary\n",
      "\n",
      "Denser Summary:\n",
      "この記事では、TextRankアルゴリズムが文抽出にどのように適用されるかについて説明されています。この手法は、自動要約を行う際の一環として、テキストから代表的な文章を特定することを目的としています。TextRankは、テキストの全体から情報を引き出して再帰的に計算されるテキスト単位のランキングを可能にするため、このタイプのアプリケーションに適しています。\n",
      "\n",
      "Below is the JSON representation of the first summary step:\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"Missing_Entities\": \"TextRankアルゴリズム;自動要約;文抽出\",\n",
      "        \"Denser_Summary\": \"この記事では、TextRankアルゴリズムが文抽出にどのように適用されるかについて説明されています。この手法は、自動要約を行う際の一環として、テキストから代表的な文章を特定することを目的としています。TextRankは、テキストの全体から情報を引き出して再帰的に計算されるテキスト単位のランキングを可能にするため、このタイプのアプリケーションに適しています。\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "\n",
      "Now, let's move on to the next round of summary enhancement.\n",
      "\n",
      "Step 1: Identify 1-3 informative Entities from the Article\n",
      "\n",
      "Missing Entities:\n",
      "1. グラフ構築\n",
      "2. 文間の関連性\n",
      "3. 内容のオーバーラップ\n",
      "\n",
      "Step 2: Write a new, more detailed summary\n",
      "\n",
      "Denser Summary:\n",
      "この記事では、自動要約のためのTextRankアルゴリズムの適用として、文抽出の問題が検討されています。このプロセスでは、まずテキストに関連するグラフを構築する必要があり、グラフの頂点はランキングされる単位、つまり文を代表しています。文間の関連性は、内容のオーバーラップに基づいて計測される「類似性」によって決定されます。この類似性は、文が持つ共通のトピックによって、他の文への「推薦」と見なされます。TextRankはこのような関連性を利用して、文を再帰的にランキングすることができます。\n",
      "\n",
      "Here's the JSON representation after the second summary:\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"Missing_Entities\": \"TextRankアルゴリズム;自動要約;文抽出\",\n",
      "        \"Denser_Summary\": \"この記事では、TextRankアルゴリズムが文抽出にどのように適用されるかについて説明されています。この手法は、自動要約を行う際の一環として、テキストから代表的な文章を特定することを目的としています。TextRankは、テキストの全体から情報を引き出して再帰的に計算されるテキスト単位のランキングを可能にするため、このタイプのアプリケーションに適しています。\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"グラフ構築;文間の関連性;内容のオーバーラップ\",\n",
      "        \"Denser_Summary\": \"この記事では、自動要約のためのTextRankアルゴリズムの適用として、文抽出の問題が検討されています。このプロセスでは、まずテキストに関連するグラフを構築する必要があり、グラフの頂点はランキングされる単位、つまり文を代表しています。文間の関連性は、内容のオーバーラップに基づいて計測される「類似性」によって決定されます。この類似性は、文が持つ共通のトピックによって、他の文への「推薦」と見なされます。TextRankはこのような関連性を利用して、文を再帰的にランキングすることができます。\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "\n",
      "Next, we will proceed with the third round of summary enhancement.\n",
      "\"generate_summary:  33.477[s]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "ステップ1: 記事から1-3の情報的実体を特定\n",
      "\n",
      "抜けている実体:\n",
      "1. グラフ構築\n",
      "2. 文間の関連性\n",
      "3. 内容のオーバーラップ\n",
      "\n",
      "ステップ2: より詳細な要約を書く\n",
      "\n",
      "より濃密な要約:\n",
      "この記事では、自動要約のためのTextRankアルゴリズムの適用として、文抽出の問題が検討されています。このプロセスでは、まずテキストに関連するグラフを構築する必要があり、グラフの頂点はランキングされる単位、つまり文を代表しています。文間の関連性は、内容のオーバーラップに基づいて計測される「類似性」によって決定されます。この類似性は、文が持つ共通のトピックによって、他の文への「推薦」と見なされます。TextRankはこのような関連性を利用して、文を再帰的にランキングすることができます。\n",
      "\n",
      "以下は2回目の要約後のJSON表現です:\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"Missing_Entities\": \"TextRankアルゴリズム;自動要約;文抽出\",\n",
      "        \"Denser_Summary\": \"この記事では、TextRankアルゴリズムが文抽出にどのように適用されるかについて説明されています。この手法は、自動要約を行う際の一環として、テキストから代表的な文章を特定することを目的としています。TextRankは、テキストの全体から情報を引き出して再帰的に計算されるテキスト単位のランキングを可能にするため、このタイプのアプリケーションに適しています。\"\n",
      "    },\n",
      "    {\n",
      "        \"Missing_Entities\": \"グラフ構築;文間の関連性;内容のオーバーラップ\",\n",
      "        \"Denser_Summary\": \"この記事では、自動要約のためのTextRankアルゴリズムの適用として、文抽出の問題が検討されています。このプロセスでは、まずテキストに関連するグラフを構築する必要があり、グラフの頂点はランキングされる単位、つまり文を代表しています。文間の関連性は、内容のオーバーラップに基づいて計測される「類似性」によって決定されます。この類似性は、文が持つ共通のトピックによって、他の文への「推薦」と見なされます。TextRankはこのような関連性を利用して、文を再帰的にランキングすることができます。\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "\n",
      "次に、3回目の要約強化に進みます。\n",
      "\"Final Answer:  30.800[s]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\"Chapter: 4 Sentence Extraction 64.277[s]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CoDのインスタンスを作成\n",
    "cod = ChainOfDensity(model_name=\"gpt-4-1106-preview\")\n",
    "\n",
    "# 各章に対してCODを適用\n",
    "for section in sections[1:-1]:\n",
    "    with Timer(prefix=f'\"Chapter: {section[\"title\"]}'):\n",
    "        # 章ごとの前提とする要約文章の生成\n",
    "        try:\n",
    "            with Timer(prefix=f'\"generate_summary: '):\n",
    "                formatted_summary = cod.generate_summary(section['content'])    #.split(\"\\n\")\n",
    "                print(f\"{formatted_summary.content}\")\n",
    "            print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during generate_summary: {e}\")\n",
    "            continue  # エラーが発生したら次のイテレーションへ\n",
    "        \n",
    "        # 最終回答\n",
    "        try:\n",
    "            with Timer(prefix=f'\"Final Answer: '):\n",
    "                final_answer = cod.generate_final_summary(str(formatted_summary))\n",
    "                print(f\"{final_answer.content}\")\n",
    "            print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during generate_final_summary: {e}\")\n",
    "            continue  # エラーが発生したら次のイテレーションへ\n",
    "        \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f2f7396-a32c-4381-a979-10f45dec0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod = ChainOfDensity(model_name=\"gpt-4-1106-preview\")\n",
    "# abst_summary = cod.generate_summary(text_from_pdf)\n",
    "# print(abst_summary.content)\n",
    "# final_answer = cod.generate_final_summary(str(abst_summary))\n",
    "# print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "# print(final_answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b09425-1c0c-4a3e-a077-b38d92237334",
   "metadata": {},
   "source": [
    "画像の抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32ab4924-12dd-4fdc-b1bc-1b0fa90ec31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fitz in /usr/local/lib/python3.10/dist-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from fitz) (5.0.8)\n",
      "Requirement already satisfied: configparser in /usr/local/lib/python3.10/dist-packages (from fitz) (6.0.0)\n",
      "Requirement already satisfied: httplib2 in /usr/lib/python3/dist-packages (from fitz) (0.20.2)\n",
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from fitz) (5.1.0)\n",
      "Requirement already satisfied: nipype in /usr/local/lib/python3.10/dist-packages (from fitz) (1.8.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.23.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz) (2.0.3)\n",
      "Requirement already satisfied: pyxnat in /usr/local/lib/python3.10/dist-packages (from fitz) (1.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.11.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from configobj->fitz) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/lib/python3/dist-packages (from httplib2->fitz) (2.4.7)\n",
      "Requirement already satisfied: packaging>=17 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (23.2)\n",
      "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (8.1.7)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.0)\n",
      "Requirement already satisfied: prov>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.0.0)\n",
      "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.8.2)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (7.0.0)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.19.2)\n",
      "Requirement already satisfied: traits!=5.0,<6.4,>=4.6 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (6.3.2)\n",
      "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.9.0)\n",
      "Requirement already satisfied: etelemetry>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (0.3.1)\n",
      "Requirement already satisfied: looseversion in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2023.3)\n",
      "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (0.18.3)\n",
      "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (4.9.3)\n",
      "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (2.31.0)\n",
      "Requirement already satisfied: ci-info>=0.2 in /usr/local/lib/python3.10/dist-packages (from etelemetry>=0.2.0->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2022.12.7)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac66e9a7-9236-4572-82ee-62659afc1a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: PyMuPDF 1.23.5\n",
      "Uninstalling PyMuPDF-1.23.5:\n",
      "  Successfully uninstalled PyMuPDF-1.23.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting PyMuPDF\n",
      "  Using cached PyMuPDF-1.23.6-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting PyMuPDFb==1.23.6 (from PyMuPDF)\n",
      "  Using cached PyMuPDFb-1.23.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Using cached PyMuPDF-1.23.6-cp310-none-manylinux2014_x86_64.whl (4.3 MB)\n",
      "Using cached PyMuPDFb-1.23.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: PyMuPDFb, PyMuPDF\n",
      "  Attempting uninstall: PyMuPDFb\n",
      "    Found existing installation: PyMuPDFb 1.23.5\n",
      "    Uninstalling PyMuPDFb-1.23.5:\n",
      "      Successfully uninstalled PyMuPDFb-1.23.5\n",
      "Successfully installed PyMuPDF-1.23.6 PyMuPDFb-1.23.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y PyMuPDF\n",
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8542ac2a-ceb1-40b5-962b-f7f5207bdb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fitz in /usr/local/lib/python3.10/dist-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from fitz) (5.0.8)\n",
      "Requirement already satisfied: configparser in /usr/local/lib/python3.10/dist-packages (from fitz) (6.0.0)\n",
      "Requirement already satisfied: httplib2 in /usr/lib/python3/dist-packages (from fitz) (0.20.2)\n",
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from fitz) (5.1.0)\n",
      "Requirement already satisfied: nipype in /usr/local/lib/python3.10/dist-packages (from fitz) (1.8.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.23.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz) (2.0.3)\n",
      "Requirement already satisfied: pyxnat in /usr/local/lib/python3.10/dist-packages (from fitz) (1.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.11.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from configobj->fitz) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/lib/python3/dist-packages (from httplib2->fitz) (2.4.7)\n",
      "Requirement already satisfied: packaging>=17 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (23.2)\n",
      "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (8.1.7)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.0)\n",
      "Requirement already satisfied: prov>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.0.0)\n",
      "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.8.2)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (7.0.0)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.19.2)\n",
      "Requirement already satisfied: traits!=5.0,<6.4,>=4.6 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (6.3.2)\n",
      "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.9.0)\n",
      "Requirement already satisfied: etelemetry>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (0.3.1)\n",
      "Requirement already satisfied: looseversion in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2023.3)\n",
      "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (0.18.3)\n",
      "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (4.9.3)\n",
      "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (2.31.0)\n",
      "Requirement already satisfied: ci-info>=0.2 in /usr/local/lib/python3.10/dist-packages (from etelemetry>=0.2.0->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2022.12.7)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5a2bd87-d500-43dd-8a3e-f10ee1ef13ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "\n",
    "# pdf_path = nougat_path\n",
    "pdf_path = \"sample.pdf\"\n",
    "doc = fitz.open(pdf_path)\n",
    "extracted_images = []\n",
    "\n",
    "for page in doc:\n",
    "    # ページからイメージを抽出\n",
    "    for img_index in page.get_images(full=True):\n",
    "        xref = img_index[0]\n",
    "        base_image = fitz.Pixmap(doc, xref)\n",
    "        pil_img = Image.frombytes(\"RGB\", [base_image.width, base_image.height], base_image.samples)\n",
    "        extracted_images.append(pil_img)\n",
    "\n",
    "# 最初の抽出された図を表示\n",
    "if extracted_images:\n",
    "    extracted_images[0].show()\n",
    "else:\n",
    "    \"このPDFには抽出可能な図が含まれていません。\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62529ee0-b571-4c87-af19-1bbfc13b991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in extracted_images:\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee433b7-9f2b-47d7-aa2f-060a4397e6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
